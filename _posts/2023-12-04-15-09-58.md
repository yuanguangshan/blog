---
title: 黄仁勋的英伟达如何推动人工智能革命
date: 2023-12-04T15:09:58+08:00
categories: [收藏]
tags: [精品]
---

How Jensen Huang’s Nvidia Is Powering the A.I. Revolution

The revelation that ChatGPT, the astonishing artificial-intelligence chatbot, had been trained on an Nvidia supercomputer spurred one of the largest single-day gains in stock-market history. When the Nasdaq opened on May 25, 2023, Nvidia’s value increased by about two hundred billion dollars. A few months earlier, Jensen Huang, Nvidia’s C.E.O., had informed investors that Nvidia had sold similar supercomputers to fifty of America’s hundred largest companies. By the close of trading, Nvidia was the sixth most valuable corporation on earth, worth more than Walmart and ExxonMobil combined. Huang’s business position can be compared to that of Samuel Brannan, the celebrated vender of prospecting supplies in San Francisco in the late eighteen-forties. “There’s a war going on out there in A.I., and Nvidia is the only arms dealer,” one Wall Street analyst said.

Huang is a patient monopolist. He drafted the paperwork for Nvidia with two other people at a Denny’s restaurant in San Jose, California, in 1993, and has run it ever since. At sixty, he is sarcastic and self-deprecating, with a Teddy-bear face and wispy gray hair. Nvidia’s main product is its graphics-processing unit, a circuit board with a powerful microchip at its core. In the beginning, Nvidia sold these G.P.U.s to video gamers, but in 2006 Huang began marketing them to the supercomputing community as well. Then, in 2013, on the basis of promising research from the academic computer-science community, Huang bet Nvidia’s future on artificial intelligence. A.I. had disappointed investors for decades, and Bryan Catanzaro, Nvidia’s lead deep-learning researcher at the time, had doubts. “I didn’t want him to fall into the same trap that the A.I. industry has had in the past,” Catanzaro told me. “But, ten years plus down the road, he was right.”

In the near future, A.I. is projected to generate movies on demand, provide tutelage to children, and teach cars to drive themselves. All of these advances will occur on Nvidia G.P.U.s, and Huang’s stake in the company is now worth more than forty billion dollars.

In September, I met Huang for breakfast at the Denny’s where Nvidia was started. (The C.E.O. of Denny’s was giving him a plaque, and a TV crew was in attendance.) Huang keeps up a semi-comic deadpan patter at all times. Chatting with our waitress, he ordered seven items, including a Super Bird sandwich and a chicken-fried steak. “You know, I used to be a dishwasher here,” he told her. “But I worked hard! Like, really hard. So I got to be a busboy.”

Huang has a practical mind-set, dislikes speculation, and has never read a science-fiction novel. He reasons from first principles about what microchips can do today, then gambles with great conviction on what they will do tomorrow. “I do everything I can not to go out of business,” he said at breakfast. “I do everything I can not to fail.” Huang believes that the basic architecture of digital computing, little changed since it was introduced by I.B.M. in the early nineteen-sixties, is now being reconceptualized. “Deep learning is not an algorithm,” he said recently. “Deep learning is a method. It’s a new way of developing software.” The evening before our breakfast, I’d watched a video in which a robot, running this new kind of software, stared at its hands in seeming recognition, then sorted a collection of colored blocks. The video had given me chills; the obsolescence of my species seemed near. Huang, rolling a pancake around a sausage with his fingers, dismissed my concerns. “I know how it works, so there’s nothing there,” he said. “It’s no different than how microwaves work.” I pressed Huang—an autonomous robot surely presents risks that a microwave oven does not. He responded that he has never worried about the technology, not once. “All it’s doing is processing data,” he said. “There are so many other things to worry about.”

In May, hundreds of industry leaders endorsed a statement that equated the risk of runaway A.I. with that of nuclear war. Huang didn’t sign it. Some economists have observed that the Industrial Revolution led to a relative decline in the global population of horses, and have wondered if A.I. might do the same to humans. “Horses have limited career options,” Huang said. “For example, horses can’t type.” As he finished eating, I expressed my concerns that, someday soon, I would feed my notes from our conversation into an intelligence engine, then watch as it produced structured, superior prose. Huang didn’t dismiss this possibility, but he assured me that I had a few years before my John Henry moment. “It will come for the fiction writers first,” he said. Then he tipped the waitress a thousand dollars, and stood up to accept his award.

Huang was born in Taiwan in 1963, but when he was nine he and his older brother were sent as unaccompanied minors to the U.S. They landed in Tacoma, Washington, to live with an uncle, before being sent to the Oneida Baptist Institute, in Kentucky, which Huang’s uncle believed was a prestigious boarding school. In fact, it was a religious reform academy. Huang was placed with a seventeen-year-old roommate. On their first night together, the older boy lifted his shirt to show Huang the numerous places where he’d been stabbed in fights. “Every student smoked, and I think I was the only boy at the school without a pocketknife,” Huang told me. His roommate was illiterate; in exchange for teaching him to read, Huang said, “he taught me how to bench-press. I ended up doing a hundred pushups every night before bed.”

Although Huang lived at the academy, he was too young to attend its classes, so he went to a nearby public school. There, he befriended Ben Bays, who lived with his five siblings in an old house with no running water. “Most of the kids at the school were children of tobacco farmers,” Bays said, “or just poor kids living in the mouth of the holler.” Huang arrived with the school year already in session, and Bays remembers the principal introducing an undersized Asian immigrant with long hair and heavily accented English. “He was a perfect target,” Bays said.

 
Huang was relentlessly bullied. “The way you described Chinese people back then was ‘Chinks,’ ” Huang told me, with no apparent emotion. “We were called that every day.” To get to school, Huang had to cross a rickety pedestrian footbridge over a river. “These swinging bridges, they were very high,” Bays said. “It was old planks, and most of them were missing.” Sometimes, when Huang was crossing the bridge, the local boys would grab the ropes and try to dislodge him. “Somehow it never seemed to affect him,” Bays said. “He just shook it off.” By the end of the school year, Bays told me, Huang was leading those same kids on adventures into the woods. Bays recalled how carefully Huang stepped around the missing planks. “Actually, it looked like he was having fun,” he said.
 

Huang credits his time at Oneida with building resiliency. “Back then, there wasn’t a counsellor to talk to,” he told me. “Back then, you just had to toughen up and move on.” In 2019, he donated a building to the school, and talked fondly of the (now gone) footbridge, neglecting to mention the bullies who had tried to toss him off it.

After a couple of years, Huang’s parents secured entry to the United States, settling in Oregon, and the brothers reunited with them. Huang excelled in high school, and was a nationally ranked table-tennis player. He belonged to the school’s math, computer, and science clubs, skipped two grades, and graduated when he was sixteen. “I did not have a girlfriend,” he said.

Huang attended Oregon State University, where he majored in electrical engineering. His lab partner in his introductory classes was Lori Mills, an earnest, nerdy undergraduate with curly brown hair. “There were, like, two hundred and fifty kids in electrical engineering, and maybe three girls,” Huang told me. Competition broke out among the male undergraduates for Mills’s attention, and Huang felt that he was at a disadvantage. “I was the youngest kid in the class,” he said. “I looked like I was about twelve.”

Every weekend, Huang would call Mills and pester her to do homework with him. “I tried to impress her—not with my looks, of course, but with my strong capability to complete homework,” he said. Mills accepted, and, after six months of homework, Huang worked up the courage to ask her out on a date. She accepted that offer, too.

Following graduation, Huang and Mills found work in Silicon Valley as microchip designers. (“She actually made more than me,” Huang said.) The two got married, and within a few years Mills had left the workforce to bring up their children. By then, Huang was running his own division, and attending graduate school at Stanford by night. He founded Nvidia in 1993, with Chris Malachowsky and Curtis Priem, two veteran microchip designers. Although Huang, then thirty, was younger than Malachowsky and Priem, both felt that he was ready to be C.E.O. “He was a fast learner,” Malachowsky said.

Malachowsky and Priem were looking to design a graphics chip, which they hoped would make competitors, in Priem’s words, “green with envy.” They called their company NVision, until they learned that the name was taken by a manufacturer of toilet paper. Huang suggested Nvidia, riffing on the Latin word invidia, meaning “envy.” He selected the Denny’s as a venue to organize the business because it was quieter than home and had cheap coffee—and also because of his experience working for the restaurant chain in Oregon in the nineteen-eighties. “I find that I think best when I’m under adversity,” Huang said. “My heart rate actually goes down. Anyone who’s dealt with rush hour in a restaurant knows what I’m talking about.”

Huang liked video games and thought that there was a market for better graphics chips. Instead of drawing pixels by hand, artists were starting to assemble three-dimensional polygons out of shapes known as “primitives,” saving time and effort but requiring new chips. Nvidia’s competitors’ primitives used triangles, but Huang and his co-founders decided to use quadrilaterals instead. This was a mistake, and it nearly sank the company: soon after the release of Nvidia’s first product, Microsoft announced that its graphics software would support only triangles.



Short on money, Huang decided that his only hope was to use the conventional triangle approach and try to beat the competition to market. In 1996, he laid off more than half the hundred people working at Nvidia, then bet the company’s remaining funds on a production run of untested microchips that he wasn’t sure would work. “It was fifty-fifty,” Huang told me, “but we were going out of business anyway.”

When the product, known as RIVA 128, hit stores, Nvidia had enough money to meet only one month of payroll. But the gamble paid off, and Nvidia sold a million RIVAs in four months. Huang encouraged his employees to continue shipping products with a sense of desperation, and for years to come he opened staff presentations with the words “Our company is thirty days from going out of business.” The phrase remains the unofficial corporate motto.

At the center of Nvidia’s headquarters, in Santa Clara, are two enormous buildings, each in the shape of a triangle with its corners trimmed. This shape is replicated in miniature throughout the building interiors, from the couches and the carpets to the splash guards in the urinals. Nvidia’s “spaceships,” as employees call the two buildings, are cavernous and filled with light, but eerie, and mostly empty; post-Covid, only about a third of the workforce shows up on any given day. Employee demographics are “diverse,” sort of—I would guess, based on a visual survey of the cafeteria at lunchtime, that about a third of the staff is South Asian, a third is East Asian, and a third is white. The workers are overwhelmingly male.

Even before the run-up in the stock price, employee surveys ranked Nvidia as one of America’s best places to work. Each building has a bar at the top, with regular happy hours, and workers are encouraged to treat their offices as flexible spaces in which to eat, code, and socialize. Nevertheless, the buildings’ interiors are immaculate—Nvidia tracks employees throughout the day with video cameras and A.I. If an employee eats a meal at a conference table, the A.I. can dispatch a janitor within an hour to clean up. At Denny’s, Huang told me to expect a world in which robots would fade into the background, like household appliances. “In the future, everything that moves will be autonomous,” he said.

The only people I saw at Nvidia who didn’t look happy were the quality-control technicians. In windowless laboratories underneath the north-campus bar, pallid young men wearing earplugs and T-shirts pushed Nvidia’s microchips to the brink of failure. The racket was unbearable, a constant whine of high-pitched fans trying to cool overheating silicon circuits. It is these chips which have made the A.I. revolution possible.

In standard computer architecture, a microchip known as a “central processing unit” does most of the work. Coders create programs, and those programs bring mathematical problems to the C.P.U., which produces one solution at a time. For decades, the major manufacturer of C.P.U.s was Intel, and Intel has tried to force Nvidia out of existence several times. “I don’t go anywhere near Intel,” Huang told me, describing their Tom and Jerry relationship. “Whenever they come near us, I pick up my chips and run.”

Nvidia has embraced an alternative approach. In 1999, the company, shortly after going public, introduced a graphics card called GeForce, which Dan Vivoli, the company’s head of marketing, called a “graphics-processing unit.” (“We invented the category so we could be the leader in it,” Vivoli said.) Unlike general-purpose C.P.U.s, the G.P.U. breaks complex mathematical tasks apart into small calculations, then processes them all at once, in a method known as parallel computing. A C.P.U. functions like a delivery truck, dropping off one package at a time; a G.P.U. is more like a fleet of motorcycles spreading across a city.

The GeForce line was a success. Its popularity was driven by the Quake video-game series, which used parallel computing to render monsters that players could shoot with a grenade launcher. (Quake II was released when I was a freshman in college, and cost me years of my life.) The Quake series also featured a “deathmatch” mode for multiplayer combat, and PC gamers, looking to gain an edge, bought new GeForce cards every time they were upgraded. In 2000, Ian Buck, a graduate student studying computer graphics at Stanford, chained thirty-two GeForce cards together to play Quake using eight projectors. “It was the first gaming rig in 8K resolution, and it took up an entire wall,” Buck told me. “It was beautiful.”

 


Buck wondered if the GeForce cards might be useful for tasks other than launching grenades at his friends. The cards came with a primitive programming tool called a shader. With a grant from DARPA, the Department of Defense’s research arm, Buck hacked the shaders to access the parallel-computing circuits below, repurposing the GeForce into a low-budget supercomputer. Soon, Buck was working for Huang.

Buck is intense and balding, and he radiates intelligence. He is a computer-science hot-rodder who has spent the past twenty years testing the limits of Nvidia chips. Human beings “think linearly. You give instructions to someone on how to get from here to Starbucks, and you give them individual steps,” he said. “You don’t give them instructions on how to get to any Starbucks location from anywhere. It’s just hard to think that way, in parallel.”
 


Since 2004, Buck has overseen the development of Nvidia’s supercomputing software package, known as CUDA. Huang’s vision was to enable CUDA to work on every GeForce card. “We were democratizing supercomputing,” Huang said.

As Buck developed the software, Nvidia’s hardware team began allocating space on the microchips for supercomputing operations. The chips contained billions of electronic transistors, which routed electricity through labyrinthine circuits to complete calculations at extraordinary speed. Arjun Prabhu, Nvidia’s lead chip engineer, compared microchip design to urban planning, with different zones of the chip dedicated to different tasks. As Tetris players do with falling blocks, Prabhu will sometimes see transistors in his sleep. “I’ve often had it where the best ideas happen on a Friday night, when I’m literally dreaming about it,” Prabhu said.

When CUDA was released, in late 2006, Wall Street reacted with dismay. Huang was bringing supercomputing to the masses, but the masses had shown no indication that they wanted such a thing. “They were spending a fortune on this new chip architecture,” Ben Gilbert, the co-host of “Acquired,” a popular Silicon Valley podcast, said. “They were spending many billions targeting an obscure corner of academic and scientific computing, which was not a large market at the time—certainly less than the billions they were pouring in.” Huang argued that the simple existence of CUDA would enlarge the supercomputing sector. This view was not widely held, and by the end of 2008 Nvidia’s stock price had declined by seventy per cent.

In speeches, Huang has cited a visit to the office of Ting-Wai Chiu, a professor of physics at National Taiwan University, as giving him confidence during this time. Chiu, seeking to simulate the evolution of matter following the Big Bang, had constructed a homemade supercomputer in a laboratory adjacent to his office. Huang arrived to find the lab littered with GeForce boxes and the computer cooled by oscillating desk fans. “Jensen is a visionary,” Chiu told me. “He made my life’s work possible.”

Chiu was the model customer, but there weren’t many like him. Downloads of CUDA hit a peak in 2009, then declined for three years. Board members worried that Nvidia’s depressed stock price would make it a target for corporate raiders. “We did everything we could to protect the company against an activist shareholder who might come in and try to break it up,” Jim Gaither, a longtime board member, told me. Dawn Hudson, a former N.F.L. marketing executive, joined the board in 2013. “It was a distinctly flat, stagnant company,” she said.

In marketing CUDA, Nvidia had sought a range of customers, including stock traders, oil prospectors, and molecular biologists. At one point, the company signed a deal with General Mills to simulate the thermal physics of cooking frozen pizza. One application that Nvidia spent little time thinking about was artificial intelligence. There didn’t seem to be much of a market.

At the beginning of the twenty-tens, A.I. was a neglected discipline. Progress in basic tasks such as image recognition and speech recognition had seen only halting progress. Within this unpopular academic field, an even less popular subfield solved problems using “neural networks”—computing structures inspired by the human brain. Many computer scientists considered neural networks to be discredited. “I was discouraged by my advisers from working on neural nets,” Catanzaro, the deep-learning researcher, told me, “because, at the time, they were considered to be outdated, and they didn’t work.”

Catanzaro described the researchers who continued to work on neural nets as “prophets in the wilderness.” One of those prophets was Geoffrey Hinton, a professor at the University of Toronto. In 2009, Hinton’s research group used Nvidia’s CUDA platform to train a neural network to recognize human speech. He was surprised by the quality of the results, which he presented at a conference later that year. He then reached out to Nvidia. “I sent an e-mail saying, ‘Look, I just told a thousand machine-learning researchers they should go and buy Nvidia cards. Can you send me a free one?’ ” Hinton told me. “They said no.”



Despite the snub, Hinton encouraged his students to use CUDA, including a Ukrainian-born protégé of his named Alex Krizhevsky, who Hinton thought was perhaps the finest programmer he’d ever met. In 2012, Krizhevsky and his research partner, Ilya Sutskever, working on a tight budget, bought two GeForce cards from Amazon. Krizhevsky then began training a visual-recognition neural network on Nvidia’s parallel-computing platform, feeding it millions of images in a single week. “He had the two G.P.U. boards whirring in his bedroom,” Hinton said. “Actually, it was his parents who paid for the quite considerable electricity costs.”

Sutskever and Krizhevsky were astonished by the cards’ capabilities. Earlier that year, researchers at Google had trained a neural net that identified videos of cats, an effort that required some sixteen thousand C.P.U.s. Sutskever and Krizhevsky had produced world-class results with just two Nvidia circuit boards. “G.P.U.s showed up and it felt like a miracle,” Sutskever told me.

AlexNet, the neural network that Krizhevsky trained in his parents’ house, can now be mentioned alongside the Wright Flyer and the Edison bulb. In 2012, Krizhevsky entered AlexNet into the annual ImageNet visual-recognition contest; neural networks were unpopular enough at the time that he was the only contestant to use this technique. AlexNet scored so well in the competition that the organizers initially wondered if Krizhevsky had somehow cheated. “That was a kind of Big Bang moment,” Hinton said. “That was the paradigm shift.”

In the decade since Krizhevsky’s nine-page description of AlexNet’s architecture was published, it has been cited more than a hundred thousand times, making it one of the most important papers in the history of computer science. (AlexNet correctly identified photographs of a scooter, a leopard, and a container ship, among other things.) Krizhevsky pioneered a number of important programming techniques, but his key finding was that a specialized G.P.U. could train neural networks up to a hundred times faster than a general-purpose C.P.U. “To do machine learning without CUDA would have just been too much trouble,” Hinton said.

Within a couple of years, every entrant in the ImageNet competition was using a neural network. By the mid-twenty-tens, neural networks trained on G.P.U.s were identifying images with ninety-six-per-cent accuracy, surpassing humans. Huang’s ten-year crusade to democratize supercomputing had succeeded. “The fact that they can solve computer vision, which is completely unstructured, leads to the question ‘What else can you teach it?’ ” Huang said to me.

The answer seemed to be: everything. Huang concluded that neural networks would revolutionize society, and that he could use CUDA to corner the market on the necessary hardware. He announced that he was once again betting the company. “He sent out an e-mail on Friday evening saying everything is going to deep learning, and that we were no longer a graphics company,” Greg Estes, a vice-president at Nvidia, told me. “By Monday morning, we were an A.I. company. Literally, it was that fast.”

 

Around the time Huang sent the e-mail, he approached Catanzaro, Nvidia’s leading A.I. researcher, with a thought experiment. “He told me to imagine he’d marched all eight thousand of Nvidia’s employees into the parking lot,” Catanzaro said. “Then he told me I was free to select anyone from the parking lot to join my team.”

Huang rarely gives interviews, and tends to deflect attention from himself. “I don’t really think I’ve done anything special here,” he told me. “It’s mostly my team.” (“He’s irreplaceable,” the board member Jim Gaither told me.) “I’m not sure why I was selected to be the C.E.O.,” Huang said. “I didn’t have any particular drive.” (“He was determined to run a business by the time he was thirty,” his co-founder Chris Malachowsky told me.) “I’m not a great speaker, really, because I’m quite introverted,” Huang said. (“He’s a great entertainer,” his friend Ben Bays told me.) “I only have one superpower—homework,” Huang said. (“He can master any subject over a weekend,” Dwight Diercks, Nvidia’s head of software, said.)

Huang prefers an agile corporate structure, with no fixed divisions or hierarchy. Instead, employees submit a weekly list of the five most important things they are working on. Brevity is encouraged, as Huang surveys these e-mails late into the night. Wandering through Nvidia’s giant campus, he often stops by the desks of junior employees and quizzes them on their work. A visit from Huang can turn a cubicle into an interrogation chamber. “Typically, in Silicon Valley, you can get away with fudging it,” the industry analyst Hans Mosesmann told me. “You can’t do that with Jensen. He will kind of lose his temper.”

Huang communicates to his staff by writing hundreds of e-mails per day, often only a few words long. One executive compared the e-mails to haiku, another to ransom notes. Huang has also developed a set of management aphorisms that he refers to regularly. When scheduling, Huang asks employees to consider “the speed of light.” This does not simply mean to move quickly; rather, employees are to consider the absolute fastest a task could conceivably be accomplished, then work backward toward an achievable goal. They are also encouraged to pursue the “zero-billion-dollar market.” This refers to exploratory products, such as CUDA, which not only do not have competitors but don’t even have obvious customers. (Huang sometimes reminded me of Kevin Costner’s character in “Field of Dreams,” who builds a baseball diamond in the middle of an Iowa cornfield, then waits for players and fans to arrive.)



Perhaps Huang’s most radical belief is that “failure must be shared.” In the early two-thousands, Nvidia shipped a faulty graphics card with a loud, overactive fan. Instead of firing the card’s product managers, Huang arranged a meeting in which the managers presented, to a few hundred people, every decision they had made that led to the fiasco. (Nvidia also distributed to the press a satirical video, starring the product managers, in which the card was repurposed as a leaf blower.) Presenting one’s failures to an audience has become a beloved ritual at Nvidia, but such corporate struggle sessions are not for everyone. “You can kind of see right away who is going to last here and who is not,” Diercks said. “If someone starts getting defensive, I know they’re not going to make it.”

Huang’s employees sometimes complain of his mercurial personality. “It’s really about what’s going on in my brain versus what’s coming out of my mouth,” Huang told me. “When the mismatch is great, then it comes out as anger.” Even when he’s calm, Huang’s intensity can be overwhelming. “Interacting with him is kind of like sticking your finger in the electric socket,” one employee said. Still, Nvidia has high employee retention. Jeff Fisher, who runs the company’s consumer division, was one of the first employees. He’s now extremely wealthy, but he continues to work. “Many of us are financial volunteers at this point,” Fisher said, “but we believe in the mission.” Both of Huang’s children pursued jobs in the hospitality industry when they were in their twenties; following years of paternal browbeating, they now have careers at Nvidia. Catanzaro at one point left for another company. A few years later, he returned. “Jensen is not an easy person to get along with all of the time,” Catanzaro said. “I’ve been afraid of Jensen sometimes, but I also know that he loves me.”

After the success of AlexNet, venture capitalists began shovelling money at A.I. “We’ve been investing in a lot of startups applying deep learning to many areas, and every single one effectively comes in building on Nvidia’s platform,” Marc Andreessen, of the firm Andreessen Horowitz, said in 2016. Around that time, Nvidia delivered its first dedicated A.I. supercomputer, the DGX-1, to a research group at OpenAI. Huang himself took the computer to OpenAI’s offices; Elon Musk, then the chairman, opened the package with a box cutter.

In 2017, researchers at Google introduced a new architecture for neural-net training called a transformer. The following year, researchers at OpenAI used Google’s framework to build the first “generative pre-trained transformer,” or G.P.T. The G.P.T. models were trained on Nvidia supercomputers, absorbing an enormous corpus of text and learning how to make humanlike connections. In late 2022, after several versions, ChatGPT was released to the public.

Since then, Nvidia has been overwhelmed with customer requests. The company’s latest A.I.-training module, known as the DGX H100, is a three-hundred-and-seventy-pound metal box that can cost up to five hundred thousand dollars. It is currently on back order for months. The DGX H100 runs five times as fast as the hardware that trained ChatGPT, and could have trained AlexNet in less than a minute. Nvidia is projected to sell half a million of the devices by the end of the year.

The more processing power one applies to a neural net, the more sophisticated its output becomes. For the most advanced A.I. models, Nvidia sells a rack of dozens of DGX H100s. If that isn’t enough, Nvidia will arrange these computers like library stacks, filling a data center with tens of millions of dollars’ worth of supercomputing equipment. There is no obvious limit to the A.I.’s capabilities. “If you allow yourself to believe that an artificial neuron is like a biological neuron, then it’s like you’re training brains,” Sutskever told me. “They should do everything we can do.” I was initially skeptical of Sutskever’s claim—I hadn’t learned to identify cats by looking at ten million reference images, and I hadn’t learned to write by scanning the complete works of humanity. But the fossil record shows that the nervous system first developed several hundred million years ago, and has been growing more sophisticated ever since. “There have been a lot of living creatures on this earth for a long time that have learned a lot of things,” Catanzaro said, “and a lot of that is written down in physical structures in your brain.”

The latest A.I.s have powers that surprise even their creators, and no one quite knows what they are capable of. (GPT-4, ChatGPT’s successor, can transform a sketch on a napkin into a functioning Web site, and has scored in the eighty-eighth percentile on the LSAT.) In the next few years, Nvidia’s hardware, by accelerating evolution to the speed of a computer-clock cycle, will train all manner of similar A.I. models. Some will manage investment portfolios; some will fly drones. Some will steal your likeness and reproduce it; some will mimic the voices of the dead. Some will act as brains for autonomous robots; some will create genetically tailored drugs. Some will write music; some will write poetry. If we aren’t careful, someday soon, one will outsmart us.

The gross profit margin on Nvidia’s equipment approaches seventy per cent. This ratio attracts competition in the manner that chum attracts sharks. Google and Tesla are developing A.I.-training hardware, as are numerous startups. One of those startups is Cerebras, which makes a “mega-chip” the size of a dinner plate. “They’re just extorting their customers, and nobody will say it out loud,” Cerebras’s C.E.O., Andrew Feldman, said of Nvidia. (Huang countered that a well-trained A.I. model can reduce customers’ overhead in other business lines. “The more you buy, the more you save,” he said.)

Nvidia’s fiercest rival is Advanced Micro Devices. Since 2014, A.M.D. has been run by Lisa Su, another gifted engineer who immigrated to the United States from Taiwan at a young age. In the years since Su became the head of the company, A.M.D.’s stock price has risen thirtyfold, making her second only to Huang as the most successful semiconductor C.E.O. of this era. Su is also Huang’s first cousin once removed.

Huang told me that he didn’t know Su growing up; he met her only after she was named C.E.O. “She’s terrific,” he said. “We’re not very competitive.” (Nvidia employees can recite the relative market share of Nvidia’s and A.M.D.’s graphics cards from memory.) Their personalities are different: Su is reserved and stoic; Huang is temperamental and expressive. “She has a great poker face,” Mosesmann, the industry analyst, said. “Jensen does not, although he’d still find a way to beat you.”



Su likes to tail the incumbent, and wait for it to falter. Unlike Huang, she is not afraid to compete with Intel, and, in the past decade, A.M.D. has captured a large portion of Intel’s C.P.U. business, a feat that analysts once regarded as impossible. Recently, Su has turned her attention to the A.I. market. “Jensen does not want to lose. He’s a driven guy,” Forrest Norrod, the executive overseeing A.M.D.’s effort, said. “But we think we can compete with Nvidia.”

On a gloomy Friday afternoon in September, I drove to an upscale resort overlooking the Pacific to watch Huang be publicly interviewed by Hao Ko, the lead architect of Nvidia’s headquarters. I arrived early to find the two men facing the ocean, engaged in quiet conversation. They were dressed nearly identically, in black leather jackets, black jeans, and black shoes, although Ko was much taller. I was hoping to catch some candid statements about the future of computing; instead, I got a six-minute roast of Ko’s wardrobe. “Look at this guy!” Huang said. “He’s dressed just like me. He’s copying me—which is smart—only his pants have too many pockets.” Ko gave a nervous chuckle, and looked down at his designer jeans, which did have a few more zippered pockets than function would strictly demand. “Simplify, man!” Huang said, before turning to me. “That’s why he’s dressed like me. I taught this guy everything he knows.” (Huang’s wardrobe is widely imitated, and earlier this year he was featured in the Style section of the Times.)



The interview was sponsored by Gensler, one of the world’s leading corporate-design firms, and there were several hundred architects in attendance. As the event approached, Huang increased the intensity of his shtick, cracking a series of weak jokes and rocking back and forth on his feet. Huang does dozens of speaking gigs a year, and had given a talk to a different audience earlier that day, but I realized that he was nervous. “I hate public speaking,” he said.

Onstage, though, he seemed relaxed and confident. He explained that the skylights on the undulating roof of his headquarters were positioned to illuminate the building while blocking direct sunlight. To calculate the design, Huang had strapped Ko into a virtual-reality headset and then attached the headset to a rack of Nvidia G.P.U.s, so that Ko could track the flow of light. “This is the world’s first building that needed a supercomputer to be possible,” Huang said.

Following the interview, Huang took questions from the audience, including one about the potential risks of A.I. “There’s the doomsday A.I.s—the A.I. that somehow jumped out of the computer and consumes tons and tons of information and learns all by itself, reshaping its attitude and sensibility, and starts making decisions on its own, including pressing buttons of all kinds,” Huang said, pantomiming pressing the buttons in the air. The room grew very quiet. “No A.I. should be able to learn without a human in the loop,” he said. One architect asked when A.I. might start to figure things out on its own. “Reasoning capability is two to three years out,” Huang said. A low murmur went through the crowd.

Afterward, I caught up with Ko. Like a lot of Huang’s jokes, the crack about teaching Ko “everything he knows” contained a pointed truth. Ko hadn’t yet made partner at Gensler when Huang chose him for the Nvidia headquarters, bypassing Ko’s boss. I asked Ko why Huang had done so. “You probably have heard stories,” Ko said. “He can be very tough. He will undress you.” Huang had no architecture experience, but he would often tell Ko that he was wrong about the building’s design. “I would say ninety per cent of architects would battle back,” Ko said. “I’m more of a listener.”

Ko recalled Huang challenging Nvidia’s engineering staff on the speed of the V.R. headset. The headset originally took five hours to render design changes; at Huang’s urging, the engineers got the speed down to ten seconds. “He was tough on them, but there was a logic to it,” Ko said. “If the headset took five hours, I’d probably settle on whatever shade of green looked adequate. If it took ten seconds, I’d take the time to pick the best shade of green there was.”

The buildings’ design won several awards and made Ko’s career. Still, Ko recalled his time on the project with mixed emotions. “The place was finished, it looks amazing, we’re doing the tour, and he’s questioning me about the placement of the water fountains,” Ko said. “He was upset because they were next to the bathrooms! That’s required by code, and this is a billion-dollar building! But he just couldn’t let it go.”

“I’m never satisfied,” Huang told me. “No matter what it is, I only see imperfections.”

I asked Huang if he was taking any gambles today that resemble the one he took twenty years ago. He responded immediately with a single word: “Omniverse.” Inspired by the V.R.-architecture gambit, the Omniverse is Nvidia’s attempt to simulate the real world at an extraordinary level of fine-grained detail. Huang has described it as an “industrial metaverse.”

Since 2018, Nvidia’s graphics cards have featured “ray-tracing,” which simulates the way that light bounces off objects to create photorealistic effects. Inside a triangle of frosted glass in Nvidia’s executive meeting center, a product-demo specialist showed me a three-dimensional rendering of a gleaming Japanese ramen shop. As the demo cycled through different points of view, light reflected off the metal counter and steam rose from a bubbling pot of broth. There was nothing to indicate that it wasn’t real.

The specialist then showed me “Diane,” a hyper-realistic digital avatar that speaks five languages. A powerful generative A.I. had studied millions of videos of people to create a composite entity. It was the imperfections that were most affecting—Diane had blackheads on her nose and trace hairs on her upper lip. The only clue that Diane wasn’t truly human was an uncanny shimmer in the whites of her eyes. “We’re working on that,” the specialist said.

Huang’s vision is to unify Nvidia’s computer-graphics research with its generative-A.I. research. As he sees it, image-generation A.I.s will soon be so sophisticated that they will be able to render three-dimensional, inhabitable worlds and populate them with realistic-seeming people. At the same time, language-processing A.I.s will be able to interpret voice commands immediately. (“The programming language of the future will be ‘human,’ ” Huang has said.) Once the technologies are united with ray-tracing, users will be able to speak whole universes into existence. Huang hopes to use such “digital twins” of our own world to safely train robots and self-driving cars. Combined with V.R. technology, the Omniverse could also allow users to inhabit bespoke realities.

I felt dizzy leaving the product demo. I thought of science fiction; I thought of the Book of Genesis. I sat on a triangular couch with the corners trimmed, and struggled to imagine the future that my daughter will inhabit. Nvidia executives were building the Manhattan Project of computer science, but when I questioned them about the wisdom of creating superhuman intelligence they looked at me as if I were questioning the utility of the washing machine. I had wondered aloud if an A.I. might someday kill someone. “Eh, electricity kills people every year,” Catanzaro said. I wondered if it might eliminate art. “It will make art better!” Diercks said. “It will make you much better at your job.” I wondered if someday soon an A.I. might become self-aware. “In order for you to be a creature, you have to be conscious. You have to have some knowledge of self, right?” Huang said. “I don’t know where that could happen.” ♦




标题：黄仁勋的英伟达如何推动人工智能革命

内容：聊天机器人ChatGPT的惊人表现，得益于在英伟达超级计算机上的训练，这一事实引发了股市历史上最大的单日涨幅之一。2023年5月25日，纳斯达克开市时，英伟达的价值增加了约两千亿美元。几个月前，英伟达的首席执行官黄仁勋告诉投资者，英伟达已经向美国最大的100家公司中的50家出售了类似的超级计算机。交易结束时，英伟达成为地球上第六大价值公司，价值超过沃尔玛和埃克森美孚的总和。黄的商业地位可以与19世纪40年代末在旧金山销售采矿用品的著名商人萨缪尔·布兰南相媲美。一位华尔街分析师说：“在人工智能领域的战争中，英伟达是唯一的军火商。”

黄是一个耐心的垄断者。1993年，他和另外两个人在加利福尼亚州圣何塞的一家丹尼餐厅起草了英伟达的文件，并从那时起一直运营着它。60岁的他，讽刺而自嘲，有着泰迪熊的面孔和稀疏的灰白头发。英伟达的主要产品是其图形处理单元，这是一块核心是强大微芯片的电路板。最初，英伟达将这些GPU卖给了视频游戏玩家，但从2006年开始，黄也开始将它们推向超级计算机社区。然后，在2013年，基于学术计算机科学社区的有前景研究，黄将英伟达的未来押注在人工智能上。人工智能几十年来让投资者失望，当时的英伟达首席深度学习研究员布莱恩·卡坦扎罗（Bryan Catanzaro）也有疑虑。“我不想让他落入人工智能行业过去的陷阱，”卡坦扎罗告诉我。 “但是，十多年后，他是对的。”

在不久的将来，人工智能有望按需生成电影，为儿童提供辅导，并教汽车自己驾驶。所有这些进步都将在英伟达的GPU上发生，而黄在公司的股份现在价值超过400亿美元。

我九月份在丹尼餐厅和黄一起吃早餐，那是英伟达创立之处。（丹尼的首席执行官正在给他颁发一个奖牌，电视台的摄影组也在场。）黄始终保持着半喜剧般的面瘫幽默。与我们的女服务员聊天时，他点了七样东西，包括超级鸟三明治和炸鸡牛排。“你知道，我以前在这里当过洗碗工，”他告诉她。“但是我工作得很努力！真的很努力。所以我升职成了侍者。”

黄有实用的心态，不

喜欢投机，从未读过科幻小说。他根据首要原则推理出微芯片今天能做什么，然后大胆地押注它们明天将做什么。“我所做的一切都是为了不让公司倒闭，”他在早餐时说。“我所做的一切都是为了不失败。”黄认为，自从IBM在20世纪60年代初引入以来，数字计算的基本架构几乎没有改变，现在正在被重新构思。“深度学习不是一种算法，”他最近说。“深度学习是一种方法。这是一种开发软件的新方式。”在我们吃早餐的前一天晚上，我看了一个视频，在视频中，一个机器人运行这种新软件，看着自己的手，似乎认出了自己，然后对一堆彩色积木进行分类。这个视频让我感到不寒而栗；我的物种似乎即将过时。黄用手指将煎饼卷在香肠上，对我的担忧不屑一顾。“我知道它是如何工作的，所以没什么，”他说。“这和微波炉的工作原理没有什么不同。”我向黄施压——一个自主机器人当然比微波炉具有更大的风险。他回应说，他从未担心过技术，一次也没有。“它所做的只是处理数据，”他说。“还有很多其他事情需要担心。”

今年五月，数百位行业领袖认可了一份声明，将失控人工智能的风险与核战争相提并论。黄没有签署它。一些经济学家观察到，工业革命导致全球马匹数量相对减少，并想知道人工智能是否会对人类产生同样的影响。“马有限的职业选择，”黄说。“例如，马不能打字。”当他吃完饭时，我表达了我的担忧，即不久的将来，我可能会将我们谈话的笔记输入到一个智能引擎中，然后看着它产生结构化、更优秀的散文。黄没有排除这种可能性，但他向我保证，在我的约翰·亨利时刻到来之前，我还有几年时间。“它会先找上小说家，”他说。然后他给女服务员小费一千美元，并站起来接受他的奖项。

黄先生于1963年出生于台湾，但在九岁时，他和他的哥哥作为未成年人独自前往美国。他们抵达华盛顿州的塔科马市，先是与一位叔叔同住，随后被送到了肯塔基州的奥奈达浸信会学院，黄的叔叔认为这是一所声誉卓著的寄宿学校。实际上，这是一所宗教改革学院。黄先生被安排与一位17岁的室友同住。在他们第一晚共处时，那位年长的男孩掀起衬衫向黄先生展示他在打斗中被刺伤的众多地方。黄先生对我说：“学校的每个学生都吸烟，我想我是学校唯一一个没有携带口袋刀的男孩。”他的室友是文盲；为了交换教他阅读，黄先生说：“他教我如何做杠铃推举。我最终每晚睡前都会做一百个俯卧撑。”

尽管黄先生住在学院里，但他年纪太小，无法参加其课程，因此他去了附近的公立学校。在那里，他与本·贝斯成为了朋友，贝斯与他的五个兄弟姐妹住在一个没有自来水的旧房子里。“学校的大多数孩子都是烟草农民的孩子，”贝斯说，“或者只是住在山沟口的穷孩子。”黄先生在学年已经开始后到达，贝斯记得校长介绍了一个身材瘦小的亚洲移民，他有一头长发，说着带有浓重口音的英语。“他是一个完美的目标，”贝斯说。

黄先生遭受了无情的欺凌。“那时候，你描述中国人的方式就是‘支那人’，”黄先生毫无情感地对我说。“我们每天都被这样叫。”为了上学，黄先生必须穿过一座摇摇晃晃的步行桥，跨过一条河。“这些摇摆的桥梁非常高，”贝斯说。“是旧木板，大多数都不见了。”有时，当黄先生穿过桥梁时，当地的男孩会抓住绳子试图让他摔下去。“不知怎的，这似乎从未影响过他，”贝斯说。“他只是把它抖掉了。”到了学年末，贝斯告诉我，黄先生带领着这些孩子一起冒险进入树林。贝斯回忆说，黄先生如何小心翼翼地绕过缺失的木板。“实际上，看起来他很享受，”他说。

黄先生将他在奥奈达的时间归功于培养了他的适应力。“那时候，没有辅导员可以谈谈，”他对我说。“那时，你只能变得坚强然后继续前进。”2019年，他向学校捐赠了一座建筑，并怀着喜爱之情谈论那座（现已不存在的）步行桥，但

没有提到试图把他从桥上扔下的恶霸。

几年后，黄先生的父母获得了进入美国的许可，他们定居在俄勒冈州，兄弟俩与他们团聚。黄先生在高中表现出色，是一名全国排名的乒乓球选手。他是学校数学、计算机和科学俱乐部的成员，跳过了两个年级，16岁就毕业了。“我没有女朋友，”他说。

黄先生就读于俄勒冈州立大学，主修电气工程。他在入门课程中的实验室搭档是洛里·米尔斯，一位认真、书呆子气的本科生，拥有卷曲的棕色头发。“就像有两百五十个孩子在电气工程专业，可能只有三个女孩，”黄先生告诉我。男本科生之间为了米尔斯的注意而爆发了竞争，黄先生觉得自己处于劣势。“我是班上最小的孩子，”他说。“我看起来像我才十二岁。”

黄先生每个周末都会给米尔斯打电话，缠着她一起做家庭作业。“我试图给她留下深刻印象——当然不是靠我的外貌，而是靠我完成家庭作业的强大能力，”他说。米尔斯接受了他的邀请，经过六个月的家庭作业后，黄先生鼓起勇气邀请她出去约会。她也接受了这个提议。

毕业后，黄先生和米尔斯在硅谷找到了作为微芯片设计师的工作。（“她实际上比我挣得多，”他说。）两人结婚后，没过几年米尔斯就离开了工作岗位，专心照顾他们的孩子。那时，黄先生已经在经营自己的部门，并在晚上在斯坦福大学读研究生。1993年，他与两位资深微芯片设计师克里斯·马拉科斯基和柯蒂斯·普里姆一起创立了英伟达公司。尽管当时只有30岁的黄先生比马拉科斯基和普里姆年轻，但两人都认为他已准备好担任首席执行官。“他学得很快，”马拉科斯基说。

马拉科斯基和普里姆希望设计一款图形芯片，他们希望这会让竞争对手，用普里姆的话说，“羡慕得发绿。”他们最初将公司命名为NVision，直到他们得知这个名字已被一家卫生纸制造商使用。黄先生提议使用Nvidia，这是源自拉丁词“invidia”，意为“嫉妒”的变体。他选择了丹尼斯餐厅作为组织业务的地点，因为那里比家里安静，咖啡便宜——还因为他在八十年代在俄勒冈州的丹尼斯餐厅工作过。“我发现在逆境中我思考得最清晰，”黄先生说。“我的心率实际上会下降。任何一个在餐厅应对高峰时段的人都知道我在说什么。”

黄先生喜欢视频游戏，认为有市场需求更好的图形芯片。艺术家们开始不再手动绘制像素，而是用被称为“原始图形”的形状组装三维多边形，节省了时间和精力，但需要新的芯片。英伟达的竞争对手使用三角形作为原始图形，但黄先生和他的合伙人决定改用四边形。这是一个错误，差点让公司倒闭：英伟达发布第一款产品后不久，微软宣布其图形软件将只支持三角形。

资金紧张的黄先生决定，他唯一的希望是使用传统的三角形方法，并尝试赶在竞争对手之前推向市场。1996年，他裁掉了英伟达一百多名员工中的一半以上，然后把公司剩余的资金押注在一批未经测试的微芯片上，他不确定这些芯片是否能工作。“那是五五开的机会，”黄先生告诉我，“但不管怎样

，我们都将要破产。”

当RIVA 128产品上市时，英伟达只有足够的资金支付一个月的工资。但这次冒险取得了成功，英伟达在四个月内售出了一百万个RIVA。黄先生鼓励员工继续以绝望的心态发货，并在未来几年中以“我们的公司距离破产还有30天”这句话开始员工演讲。这句话仍然是非官方的企业座右铭。

英伟达总部位于圣克拉拉，中心有两座巨大的建筑，每座都呈三角形，角被削平。这种形状在建筑内部的微缩版本中被复制，从沙发和地毯到小便池的挡水板。英伟达的“太空船”，正如员工所称的两座建筑，宽敞且充满光线，但有些诡异，而且大部分时间空无一人；疫情后，只有大约三分之一的员工每天上班。员工人数“多样化”，大致上——我根据午餐时间在食堂的视觉调查估计，大约三分之一的员工是南亚人，三分之一是东亚人，三分之一是白人。工人主要是男性。

即使在股价飙升之前，员工调查也将英伟达评为美国最佳工作场所之一。每栋建筑顶部都有一个酒吧，定期举行欢乐时光，鼓励员工将办公室作为灵活的空间，用于吃饭、编码和社交。然而，建筑的内部非常整洁——英伟达通过摄像头和人工智能全天候追踪员工。如果员工在会议桌上用餐，人工智能可以在一小时内派遣清洁工来清理。在丹尼斯，黄先生告诉我要期待一个机器人像家用电器一样融入背景的世界。“未来，所有移动的东西都将是自动的，”他说。

我在英伟达看到的唯一看起来不开心的人是质量控制技术员。在北校区酒吧下面的无窗实验室里，苍白的年轻男子戴着耳塞和T恤，将英伟达的微芯片推向崩溃的边缘。噪音难以忍受，持续不断的高音风扇试图冷却过热的硅电路。正是这些芯片使人工智能革命成为可能。

在标准计算机架构中，称为“中央处理单元”的微芯片完成了大部分工作。编程人员创建程序，这些程序将数学问题带给CPU，CPU一次产生一个解决方案。几十年来，CPU的主要制造商是英特尔，英特尔曾多次试图将英伟达逼出市场。“我不会靠近英特尔，”黄先生告诉我，描述了他们之间的猫鼠游戏。“每当他们靠近我们，我就拿起我的芯片跑。”

英伟达采用了另一种方法。1999年，该公司在上市后不久推出了一款名为GeForce的图形卡，公司市场部负责人丹·维沃利称其为

“图形处理单元”（“我们发明了这个类别，所以我们可以成为其中的领导者，”维沃利说。）与通用CPU不同，GPU将复杂的数学任务分解成小计算，然后同时处理，这种方法被称为并行计算。CPU的功能就像一辆递送卡车，一次送一个包裹；GPU更像是在城市中四处穿梭的摩托车队。

GeForce系列非常成功。其受欢迎程度得益于Quake视频游戏系列，该系列使用并行计算来渲染玩家可以用榴弹发射器射击的怪物。（当我大一时，Quake II发布了，这让我浪费了好几年的生命。）Quake系列还提供了多人战斗的“死亡竞赛”模式，PC游戏玩家为了获得优势，每次GeForce升级时都会购买新的显卡。2000年，斯坦福大学计算机图形学研究生伊恩·巴克将三十二张GeForce卡串联在一起，使用八个投影仪玩Quake。“这是第一个8K分辨率的游戏装置，它占据了整面墙，”巴克告诉我。“它很美。”

巴克想知道GeForce卡是否可用于除了向朋友发射榴弹以外的任务。这些卡带有一个原始的编程工具，称为着色器。在国防部高级研究计划局（DARPA）的资助下，巴克黑客攻击着色器以访问下面的并行计算电路，将GeForce重新利用为低成本超级计算机。不久，巴克就开始为黄先生工作。

巴克是个紧张而秃顶的人，智慧四射。他是一位计算机科学热衷者，过去二十年一直在测试英伟达芯片的极限。人类“线性思维。你给某人指示如何从这里到星巴克，并给他们逐步说明，”他说。“你不会给他们任何地方到任何星巴克位置的指示。以并行方式思考很难。”

自2004年以来，巴克一直负责英伟达超级计算软件包CUDA的开发。黄先生的愿景是使CUDA在每张GeForce卡上都能工作。“我们正在民主化超级计算，”黄先生说。

随着巴克开发软件，英伟达的硬件团队开始在微芯片上分配空间用于超级计算操作。芯片包含数十亿电子晶体管，它们通过迷宫般的电路路由电流来以惊人的速度完成计算。英伟达首席芯片工程师阿尔贾恩·普拉布将微芯片设计比作城市规划，芯片的不同区域专用于不同任务。正如俄罗斯方块玩家做的那样，普拉布有时会在梦中看到晶体管。“我经常梦到周五晚上有最好的想法，”普拉布说。

当CUDA在2006年底发布时，华尔街对此感到失望。黄先生将超级计算带给大众，但大众似乎没有表现出他们想要这样的东西。本·吉尔伯特（Ben Gilbert），硅谷热门播客《Acquired》的联合主持人说：“他们在这种新的芯片架构上投入了大量资金。他们投入了数十亿美元，瞄准的是学术和科学计算的一个模糊角落，那时这不是一个大市场——当然比他们投入的数十亿要少。”黄先生认为，CUDA的存在本身将扩大超级计算领域。这种观点并不普遍，到2008年底，英伟达的股价下跌了百分之七十。

黄先生在演讲中提到，他访问国立台湾大学物理学教授邱廷威（Ting-Wai Chiu）的办公室，这让他在这段时间里充满信心。邱廷威为了模拟大爆炸后物质的演化，在他办公室旁的实验室里构建了一个自制超级计算机。黄先生到达时发现实验室里到处都是GeForce盒子，计算机由摇头风扇冷却。“Jensen是一个有远见的人，”邱廷威对我说。“他使我的一生工作成为可能。”

邱廷威是理想客户，但像他这样的人并不多。CUDA的下载量在2009年达到高峰，然后连续三年下降。董事会成员担心英伟达股价下跌会使其成为企业掠夺者的目标。“我们尽一切努力保护公司免受可能进入并试图拆分它的激进股东的影响，”长期董事会成员吉姆·盖瑟（Jim Gaither）对我说。前NFL市场执行官唐·哈德森（Dawn Hudson）于2013年加入董事会。“那是一个明显平淡、停滞的公司，”她说。

在市场推广CUDA时，英伟达寻求各种客户，包括股票交易员、石油勘探者和分子生物学家。公司一度与通用磨坊签订了一项协议，模拟烹饪冷冻比萨的热物理学。英伟达几乎没有花时间考虑人工智能方面的应用。似乎没有太大的市场。

在二十世纪初，人工智能是一个被忽视的领域。在图像识别和语音识别等基本任务方面的进展只是缓慢的。在这个不受欢迎的学术领域中，一个更不受欢迎的子领域使用“神经网络”解决问题——这是一种受到人脑启发的计算结构。许多计算机科学家认为神经网络已被证明是无效的。“我的导师劝我不要研究神经网络，”深度学习研究员卡坦扎罗（Catanzaro）对我说，“因为当时，它们被认为是过时的，而且不起作用。”

卡坦扎罗将继续研究神

经网络的研究人员描述为“荒野中的先知”。其中一位先知是多伦多大学的教授杰弗里·辛顿（Geoffrey Hinton）。2009年，辛顿的研究小组使用英伟达的CUDA平台训练一个神经网络来识别人类语音。他对结果的质量感到惊讶，并在当年的一个会议上展示了这些结果。然后他联系了英伟达。“我发了一封电子邮件说，‘看，我刚刚告诉了一千名机器学习研究人员他们应该去买英伟达卡。你能给我寄一个免费的吗？’”辛顿对我说。“他们说不。”

尽管受到冷落，辛顿鼓励他的学生使用CUDA，包括他的乌克兰出生的门徒亚历克斯·克里兹涅夫斯基（Alex Krizhevsky），辛顿认为他可能是他见过的最优秀的程序员。2012年，克里兹涅夫斯基和他的研究伙伴伊利亚·苏茨凯弗（Ilya Sutskever）在预算紧张的情况下，从亚马逊购买了两张GeForce卡。克里兹涅夫斯基开始在英伟达的并行计算平台上训练一个视觉识别神经网络，一周内向其输入数百万图像。“他在卧室里有两个GPU板在嗡嗡作响，”辛顿说。“实际上，是他的父母支付了相当可观的电费。”

苏茨凯弗和克里兹涅夫斯基对卡的能力感到惊讶。那年早些时候，谷歌的研究人员训练了一个神经网络，识别猫的视频，这需要约一万六千个CPU。苏茨凯弗和克里兹涅夫斯基仅使用两个英伟达电路板就取得了世界级的成果。“GPU出现了，感觉就像一个奇迹，”苏茨凯弗对我说。

克里兹涅夫斯基在父母家中训练的神经网络AlexNet，现在可以与莱特飞行器和爱迪生电灯泡相提并论。2012年，克里兹涅夫斯基将AlexNet投入到年度ImageNet视觉识别大赛中；当时神经网络不够流行，他是唯一使用这种技术的参赛者。AlexNet在比赛中的表现非常好，以至于组织者最初怀疑克里兹涅夫斯基是否作弊。“那是一种大爆炸时刻，”辛顿说。“那是范式转变。”

自从Krizhevsky发表了关于AlexNet架构的九页描述以来的十年间，该文献被引用了超过十万次，成为计算机科学历史上最重要的论文之一。（AlexNet正确识别了摩托车、豹子和集装箱船等物体的照片。）Krizhevsky开创了许多重要的编程技术，但他的关键发现是，专用的GPU能比通用CPU快上百倍地训练神经网络。“没有CUDA，做机器学习就太麻烦了，”Hinton说。

在接下来的几年里，ImageNet竞赛的每个参赛者都在使用神经网络。到了二十十年代中期，使用GPU训练的神经网络在图像识别上的准确度达到了96%，超过了人类。Huang为使超级计算民主化而进行的十年长征取得了成功。“他们能解决完全无结构的计算机视觉问题，这引出了一个问题：‘你还能教它做什么？’”Huang对我说。

答案似乎是：一切。Huang得出结论，神经网络将彻底改变社会，并且他可以使用CUDA来垄断必要硬件的市场。他宣布他再次把公司的未来押注在上面。“他在周五晚上发出一封电子邮件说，一切都转向深度学习，我们不再是一家图形公司，”Nvidia的副总裁Greg Estes告诉我。“到了周一早上，我们就成了一家AI公司。真的就是这么快。”

大约在Huang发送电子邮件的时候，他找到了Nvidia的首席AI研究员Catanzaro，进行了一个思想实验。“他让我想象，他把Nvidia的八千名员工都带到了停车场，”Catanzaro说。“然后他告诉我，我可以自由选择任何一个停车场的人加入我的团队。”

Huang很少接受采访，倾向于把注意力转移开自己。“我真的不认为我在这里做了什么特别的事情，”他告诉我。“主要是我的团队。”（“他是不可替代的，”董事会成员Jim Gaither告诉我。）“我不确定为什么我被选为CEO，”Huang说。“我没有特别的动力。”（“他决心在三十岁前经营一家企业，”他的联合创始人Chris Malachowsky告诉我。）“我不是一个很好的演讲者，因为我相当内向，”Huang说。（“他是个伟大的娱乐家，”他的朋友Ben Bays告诉我。）“我只有一个超能力——做功课，”Huang说。（“他可以在一个周末掌握任何主题，”Nvidia的软件负责人Dwight Diercks说。）

Huang更喜欢一个敏捷的公司结构，没有固定的部门或层级。相反，员工每周提交他们正在进行的五件最重要的事情的清单。简洁被鼓励，因为Huang会在深夜检查这些电子邮件。他经常在Nvidia巨大的校园里漫步，经常停下来询问初级员工的工作情况。Huang的访问可以把一个隔间变成审讯室。“通常在硅谷，你可以混淆视听，

”行业分析师Hans Mosesmann告诉我。“但是你不能对Jensen那样做。他会有点失去耐心。”

Huang通过每天写数百封电子邮件与员工沟通，通常只有几个词。一位高管将这些电子邮件比作俳句，另一位则比作勒索信。Huang还发展了一套他经常引用的管理格言。在安排日程时，Huang要求员工考虑“光速”。这不仅仅意味着要快速行动；相反，员工应该考虑一个任务可以想象的最快完成速度，然后向后退步，制定一个可实现的目标。他们还被鼓励追求“零亿美元市场”。这是指探索性产品，如CUDA，它们不仅没有竞争对手，甚至没有明显的客户。（Huang有时让我想起了电影《梦幻成真》中Kevin Costner扮演的角色，他在爱荷华州的一片玉米田中建了一个棒球场，然后等待球员和球迷的到来。）

也许Huang最激进的信念是“失败必须共享”。在21世纪初，Nvidia发布了一款带有响亮、过度活跃的风扇的有缺陷的显卡。Huang没有解雇这张卡的产品经理，而是安排了一个会议，在几百人面前，这些经理介绍了他们做出导致这场灾难的每一个决策。（Nvidia还向媒体分发了一部讽刺视频，由产品经理主演，视频中将该卡改造成吹叶机。）在Nvidia，向观众展示自己的失败已成为一种受欢迎的仪式，但这样的公司斗争并不适合每个人。“你可以很快看出谁会在这里持久，谁不会，”Diercks说。“如果有人开始变得防御性，我知道他们不会成功。”

Huang的员工有时抱怨他多变的个性。“这真的是关于我大脑中的想法与我嘴里说出的话之间的不匹配，”Huang告诉我。“当不匹配很大时，它就表现为愤怒。”即使他平静时，Huang的强度也可能让人难以承受。“与他互动有点像把手指插进电插座，”一位员工说。尽管如此，Nvidia的员工留存率很高。负责公司消费者部门的Jeff Fisher是最早的员工之一。他现在非常富有，但他继续工作。“我们很多人现在都是出于对使命的信仰而自愿财务上支持公司，”Fisher说。Huang的两个孩子在二十多岁时都追求酒店业的工作；在经历了多年的父亲斥责后，他们现在都在Nvidia工作。Catanzaro曾经离开去另一家公司。几年后，他回来了。“Jensen并不是一直都容易相处，”Catanzaro说。“我有时候害怕Jensen，但我也知道他爱我。”

在AlexNet成功之后，风险投资家开始向AI领域投入大量资金。“我们一直在投资很多初创公司，将深度学习应用于许多领域，每一个基本上都是建立在Nvidia平台上的，”Andreessen Horowitz的Marc Andreessen在2016年说。大约在那个时候，Nvidia向Open

AI的一个研究小组交付了其第一台专用AI超级计算机DGX-1。Huang亲自将这台计算机送到OpenAI的办公室；当时的主席Elon Musk用裁纸刀打开了包裹。

2017年，谷歌的研究人员引入了一种名为变压器的新型神经网络训练架构。次年，OpenAI的研究人员使用谷歌的框架构建了第一个“生成式预训练变压器”（GPT）。GPT模型在Nvidia的超级计算机上训练，吸收了大量的文本语料库，并学会了如何进行类似人类的联系。在2022年底，经过几个版本之后，ChatGPT向公众发布。

此后，Nvidia的客户请求激增。该公司最新的AI训练模块，称为DGX H100，是一个重达370磅的金属盒，售价高达50万美元。目前该产品已经积压了几个月。DGX H100的运行速度是训练ChatGPT的硬件的五倍，可以在不到一分钟的时间内训练AlexNet。预计Nvidia将在今年年底前销售50万台这样的设备。

对神经网络施加的处理能力越多，其输出就越复杂。对于最先进的AI模型，Nvidia销售一排排DGX H100。如果这还不够，Nvidia将这些计算机像图书馆书架一样排列，用价值数千万美元的超级计算设备填满数据中心。AI的能力似乎没有明显的极限。“如果你允许自己相信一个人工神经元就像一个生物神经元，那就好像你在训练大脑，”Sutskever对我说。“它们应该能做我们能做的一切。”我最初对Sutskever的说法持怀疑态度——我没有通过查看一千万个参考图像来学习识别猫，我也没有通过扫描人类的全部作品来学习写作。但化石记录显示，神经系统首次发展是在几亿年前，并且自那以后一直在变得更加复杂。“地球上已经有了很多生物，它们学到了很多东西，”Catanzaro说，“这些都记录在你大脑中的物理结构里。”

最新的AI具有连其创造者也感到惊讶的能力，没有人完全知道它们能做什么。（GPT-4，ChatGPT的继任者，可以将餐巾上的草图变成一个功能性的网站，并在法学院入学考试上取得了88分。）在未来几年中，Nvidia的硬件将以计算机时钟周期的速度加速演化，培训各种类似的AI模型。有些将管理投资组合；有些将飞行无人机。有些会盗用你的肖像并复制它；有些会模仿死者的声音。有些将作为自主机器人的大脑；有些将创造基因定制药物。有些将写音乐；有些将写诗。如果我们不小心，很快就会有一个超越我们智慧的存在。

Nvidia设备的毛利率接近70%。这种比例吸引了竞争，就像鱼饵吸引鲨鱼一样。谷歌和特斯拉都在开发AI训练硬件，许多初创公司也是如此。其中一个初创公司是Cerebras，它制造了一个有着晚餐盘大小的“超大芯片”。Cerebras的首席执行官Andrew Feldman评价Nvidia说：“他们只是在敲诈他们的客户，没有人会大声说出来。”（Huang回应说，一个训练有素的AI模型可以减少客户在其他业务线上的开销。“你买得越多，节省得越多，”他说。）

Nvidia最强大的竞争对手是Advanced Micro Devices（AMD）。自2014年以来，AMD由另一位年轻时从台湾移民到美国的才华横溢的工程师Lisa Su领导。自Su成为公司总裁以来，AMD的股价已经上涨了三十倍，使她仅次于Huang，成为这个时代最成功的半导体公司首席执行官。Su也是Huang的堂兄弟。

黄仁勋（Jensen Huang）告诉我，他小时候并不认识苏姿丰（Lisa Su）；他只是在她被任命为CEO后才见过她。“她很了不起，”他说。“我们并不是很有竞争性。”（Nvidia的员工能够凭记忆背诵Nvidia和AMD显卡的相对市场份额。）他们的个性不同：苏姿丰沉稳且坚韧；黄仁勋则情绪化且富有表现力。“她有很棒的扑克脸，”行业分析师Mosesmann说。“Jensen没有，尽管他还是会找到办法打败你。”

苏姿丰喜欢尾随领先者，等待其失误。不同于黄仁勋，她不怕与英特尔竞争，而在过去十年中，AMD已经夺取了英特尔大部分的CPU业务，这是分析师曾认为不可能的壮举。最近，苏姿丰将注意力转向了AI市场。“Jensen不想输。他是一个有驱动力的人，”负责AMD努力的高管Norrod说。“但我们认为我们可以与Nvidia竞争。”

一个阴郁的九月周五下午，我开车去一个俯瞰太平洋的高档度假村，观看黄仁勋被Nvidia总部的主要建筑师Hao Ko公开采访。我提早到达，发现两人面向大海，正在安静地交谈。他们几乎穿着一样，都是黑色皮夹克、黑色牛仔裤和黑色鞋子，尽管Ko要高得多。我希望捕捉到一些关于计算未来的坦率陈述；相反，我听到的是对Ko服装的六分钟吐槽。“看这家伙！”黄仁勋说。“他的穿着就像我。他在模仿我——这很聪明——只是他的裤子口袋太多了。”Ko紧张地笑了笑，低头看着他的设计师牛仔裤，确实比实际功能所需的拉链口袋多。“简化点，伙计！”黄仁勋在转向我之前说道。“这就是为什么他穿得像我。我教会了他一切。”（黄仁勋的衣着风格被广泛模仿，今年早些时候他还出现在了《纽约时报》的风格版块。）

这次采访由世界领先的企业设计公司Gensler赞助，有几百名建筑师参加。随着活动的临近，黄仁勋加大了他的表演强度，开了一系列平淡的笑话，来回踱步。黄仁勋每年都会做几十次演讲，而且当天早些时候已经对另一个听众发表了演讲，但我意识到他很紧张。“我讨厌公开演讲，”他说。

然而，一上台，他看起来就放松和自信了。他解释说，他总部那起伏的屋顶上的天窗被放置得恰到好处，可以照亮建筑物同时阻挡直射阳光。为了计算设计，黄仁勋让Ko戴上虚拟现实头盔，然

后将头盔连接到一排Nvidia GPU上，这样Ko就可以追踪光线的流动。“这是世界上第一个需要超级计算机才可能实现的建筑，”黄仁勋说。

采访结束后，黄仁勋回答了观众的问题，包括有关AI潜在风险的问题。“有末日AI——那种不知怎么地从电脑里跳出来的AI，它消耗了大量信息并自己学习，重塑自己的态度和敏感度，并开始独立做出决策，包括按下各种按钮，”黄仁勋说，模仿着在空中按按钮。房间变得非常安静。“没有AI应该在没有人类参与的情况下学习，”他说。一位建筑师问AI何时可能开始独立解决问题。“推理能力还有两到三年，”黄仁勋说。人群中传来低沉的嘀咕声。

之后，我赶上了Ko。和黄仁勋的许多笑话一样，关于教会Ko“他所知道的一切”的玩笑也包含了一个尖锐的真理。当黄仁勋选择他为Nvidia总部设计时，Ko还没有成为Gensler的合伙人，绕过了Ko的老板。我问Ko黄仁勋为什么这样做。“你可能听说过一些故事，”Ko说。“他可能很严厉。他会揭穿你。”黄仁勋没有建筑经验，但他经常告诉Ko，他对建筑设计的看法是错误的。“我会说90%的建筑师会反击，”Ko说。“我更喜欢倾听。”

Ko回忆说，黄仁勋对Nvidia工程团队在VR头盔的速度上提出挑战。最初，头盔需要五个小时来渲染设计变化；在黄仁勋的敦促下，工程师们将速度提高到了十秒。“他对他们很严格，但这是有逻辑的，”Ko说。“如果头盔需要五个小时，我可能会满足于选择看起来合适的任何绿色阴影。如果需要十秒，我会花时间选择最好的绿色。”

这些建筑的设计赢得了几个奖项，也使Ko的职业生涯腾飞。然而，Ko对这个项目的回忆带着复杂的情感。“这个地方完工了，看起来很棒，我们在参观时，他在质疑我关于饮水机的位置，”Ko说。“他很不高兴，因为饮水机在洗手间旁边！这是规定要求的，而这是一个价值十亿美元的建筑！但他就是放不下。”

“我从不满足，”黄仁勋告诉我。“无论是什么，我只看到不完美。”

我问黄仁勋他今天是否有任何类似二十年前那样的冒险。他立即用一个词回答：“Omniverse。”受到VR建筑策略的启发，Omniverse是Nvidia试图以极其细腻的细节模拟真实世界的尝试。黄仁勋将其描述为“工业元宇宙”。

自2018年以来，Nvidia的显卡已经具备了“光线追踪”功能，这种技术模拟光线如何从物体上反射以创造出逼真的效果。在Nvidia行政会议中心一个三角形磨砂玻璃内部，一位产品演示专家向我展示了一家闪闪发光的日式拉面店的三维渲染图。随着演示从不同视角轮换，光线从金属柜台上反射，蒸汽从一锅沸腾的汤中升起。没有任何迹象表明这不是真实的。

接着，专家向我展示了“Diane”，一个会说五种语言的超写实数字化头像。一个强大的生成型AI已经研究了数百万个人的视频，创造了这个复合实体。最令人印象深刻的是它的不完美之处——Diane的鼻子上有黑头，上唇有细小的毛发。唯一表明Diane不是真人的线索是她眼睛白色部分中不可思议的闪光。“我们正在努力解决这个问题，”专家说。

黄仁勋的愿景是将Nvidia的计算机图形研究与其生成型AI研究结合起来。在他看来，图像生成AI很快就会变得如此复杂，以至于它们能够渲染出三维、可居住的世界，并用看起来逼真的人填充它们。与此同时，语言处理AI将能够立即解释语音命令。（“未来的编程语言将是‘人类’，”黄仁勋曾说。）一旦这些技术与光线追踪结合起来，用户将能够把整个宇宙说成现实。黄仁勋希望利用这样的我们自己世界的“数字孪生体”来安全地训练机器人和自动驾驶汽车。结合虚拟现实技术，Omniverse也可以让用户居住在定制的现实中。

离开产品演示后，我感到有些头晕。我想到了科幻小说；我想到了《创世纪》。我坐在一个削去角落的三角形沙发上，努力想象我女儿将居住的未来。Nvidia的高管们正在建造计算机科学的曼哈顿计划，但当我质疑他们创造超人智能的智慧时，他们看着我，好像我在质疑洗衣机的用处一样。我曾大声疑问，AI是否可能有一天会杀死某人。“嗯，电每年都会杀死人，”Catanzaro说。我想知道它是否可能消灭艺术。“它会让艺术更好！”Diercks说。“它会让你的工作做得更好。”我想知道AI是否可能很快就会变得自我意识。“为了成为一个生物，你必须有意识。你必须对自己有所了解，对吗？”黄仁勋说。“我不知道那可能在哪里发生。”♦