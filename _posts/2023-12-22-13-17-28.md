---
title: 使用ChatGPT之后，为什么也开始害怕现在AI技术？
date: 2023-12-22T13:17:28+08:00
categories: [收藏]
tags: [精品]
---

万字长文专访“AI之父”Geoffrey Hinton:​ 我使用ChatGPT之后，为什么也开始害怕现在AI技术？
 
Geoffrey Hinton has spent a lifetime teaching computers to learn. Now he worries that artificial brains are better than ours.

AI之父Geoffrey Hinton（杰弗里·辛顿），他毕生致力于教授计算机学习。如今，他担心人工智能的大脑可能比我们的更优秀。Hinton对于他的工作及其对未来影响的看法不仅揭示了技术的进步，还体现了他对于人工智能发展潜在伦理问题的担忧。

文章生动地叙述了复杂的科学概念，并通过具体例子使其易于理解，有助于普及科学知识。此外，对人工智能未来的思考激发了关于技术伦理、责任和创新的重要讨论，同时也引发了对人类与机器关系及探索未知的深入思考。整体而言，这篇文章不仅是科技的介绍，更是一次深入了解业界领袖思想的机会，对所有对科技、未来和伦理感兴趣的读者来说，都是一次宝贵的阅读体验

原文如下：

在我们的大脑中，神经元通过各种大小的网络相互连接。无论是行动还是思考，这些网络都在不断变化：神经元被纳入或排除，它们之间的联系变得更紧密或逐渐淡化。这个过程无时无刻不在进行——就像现在，当你阅读这段文字时一样——其规模之大令人难以置信。你的大脑中大约有八十亿神经元，它们共同形成了超过一百万亿的连接。你的头骨里仿佛包含了一个星系，其中的星座不断变换。

被誉为“人工智能之父”的计算机科学家杰弗里·辛顿(Geoffrey Hinton)递给我一根手杖说：“你可能会用到这个。”接着，他带着我沿着一条穿过树林通向海岸的小路前进。我们穿过一个阴凉的空地，经过几间小棚子，然后沿着石阶走向一个小码头。“这里有点滑，”Hinton在我们下降时提醒我。

新知识通过细微的调整融入我们现有的神经网络。有时这些调整是暂时的：比如在派对上遇到的陌生人，他的名字可能只会短暂留在你的记忆中。但如果这个陌生人后来成为了你的伴侣，这些记忆就可能伴随你一生。因为新旧知识的融合，你已知的内容影响着你的学习。例如，如果有人在派对上跟你谈起他去阿姆斯特丹的旅行，第二天你在博物馆可能会不自觉地被吸引到维米尔的画作前。就这样，微小的变化可能引发深远的转变。

“我们曾在这里举办过一次篝火晚会，”Hinton说。我们站在安大略省乔治亚湾的一块岩石上，这里向西延伸至休伦湖。湖面上散布着岛屿，其中一个就是Hinton在2013年，65岁时买下的。那是在他将一个三人创业公司以四千四百万美元的价格卖给谷歌之后。在此之前，他在多伦多大学担任计算机科学教授长达三十年，是神经网络这一不太引人注目的子领域的领军人物。这个领域的灵感源于大脑中神经元的连接方式。由于人工神经网络在承担的任务上只取得了适度的成功，如图像分类、语音识别等，大多数研究人员认为它们顶多有点有趣，或者是浪费时间。“我们的神经网络做不到比一个孩子更好，”Hinton回忆道。在八十年代，当他看《终结者》时，他并不介意电影中的Skynet是一个神经网络；反而，他对这项技术被描绘成有前途的感到高兴。

在篝火留下的小坑洼处，热量造成的裂缝从石头中向外辐射。Hinton，这位高大、苗条的英国人，用手杖轻轻戳了戳那里。作为一个科学家，他总是对身边发生的事情充满好奇，无论是动物的生活、湾区的水流，还是岛上的地质。“我在木头下放了一层钢筋网，让空气进入，火势变得足够猛烈，以至于金属都变软了，”他惊奇地说。“那是一场真正的火，值得骄傲！”

几十年来，Hinton一直在构建更大、更巧妙的神经网络。他想出了新的训练方法，帮助它们不断进步。他招募了研究生，说服他们神经网络不是一条死路。他认为自己是参与了一个可能在他去世后的一个世纪才会实现的长远项目。同时，他也经历了成为寡夫和独自抚养两个孩子的生活。在一个特别艰难的时期，家庭和研究的双重压力让他感到不堪重负，他认为自己已经尽力了。“我在四十六岁时觉得自己已经走到尽头了，”他说。他没想到大约十年前，神经网络技术会突然取得飞跃。计算机变得更快，神经网络开始利用互联网上的数据进行语音转录、玩游戏、翻译语言，甚至驾驶汽车。在Hinton的公司被收购时，人工智能的热潮开始了，诞生了像OpenAI的ChatGPT和谷歌的Bard这样的系统，许多人认为这些系统开始以不可预测的方式改变世界。

Hinton沿着海岸出发，我跟在他后面，脚下的岩石不稳地移动。“看这个，”他说。他站在一个凹凸不平、巨大如人的石头前，挡住了我们的路。“过去的方法是这样的。你把手杖扔到石头的另一边”——他把手杖扔了过去——“然后这里和这里有脚踏点，这里有手抓点。”我看着他熟练地爬过去，然后我也更小心翼翼地采取了同样的步骤。

我们学习的时候，大脑中的神经元网络就会发生变化。但这个过程究竟是怎样的呢？像辛顿这样的研究者，通过计算机工作，试图找到神经网络的“学习算法”，这些程序可以让人工神经元之间的连接在统计上的“权重”发生变化，以此吸收新知识。1949年，心理学家唐纳德·赫布提出了一个简单的学习规则，通常被概括为“一起触发的神经元会一起连接。”一旦你大脑中的一组神经元同步激活，它们下次再这样做的可能性就更大；这有助于解释为什么第二次做同一件事会更容易。但很快就明显，计算机化的神经网络需要采用不同的方法来解决复杂问题。作为60年代和70年代的年轻研究者，Hinton在笔记本上绘制神经元网络，想象新知识如何到达它们的边界。一个由几百个人工神经元组成的网络如何存储一个概念？如果这个概念有缺陷，它将如何进行修正？

我们绕着海岸走到辛顿的小屋，这是岛上唯一的一间。小屋用玻璃封闭，建在一排宽阔、深色的岩石楼梯上。“有一次，我们来到这里，一条巨大的水蛇探出头来，”Hinton回忆道。这是他的美好记忆。他的父亲，一位著名的昆虫学家，曾命名了一个鲜为人知的变态阶段，他在Hinton心中培养了对冷血动物的喜爱。小时候，他和父亲在车库里养了一个充满蝰蛇、乌龟、青蛙、蟾蜍和蜥蜴的坑。现在，辛顿在岛上——他经常在温暖的月份待在那里——有时会发现蛇，并把它们带进屋里，在一个玻璃容器里观察它们。他是一个善于观察非人类思维的人，因为他一生都在从基础上思考思考。

今年早些时候，Hinton离开了谷歌，他自从公司被收购以来就在那里工作。他对人工智能可能带来的危害感到担忧，并开始在采访中谈论这项技术可能对人类构成的“存在性威胁”。他使用 ChatGPT 越多，就越感到不安。这个人工智能系统是基于大量人类写作的语料库训练而成的。有一天，福克斯新闻的某人联系他，想就人工智能进行采访。Hinton喜欢用讽刺的简短回复来回应电子邮件——比如在收到加拿大情报机构的一封长邮件后，他回复说：“斯诺登是我的英雄”——他开始尝试一些俏皮的回复。最后，他写道：“福克斯新闻是个矛盾体。”接着，他突发奇想，问 ChatGPT 是否能解释他的笑话。系统告诉他，他的句子暗示福克斯新闻是假新闻，当他指出“白痴”前的空格时，系统解释说福克斯新闻像药物奥施康定一样令人上瘾。辛顿对此感到惊讶。这种理解水平似乎标志着人工智能进入了一个新时代。

人工智能的兴起引发了众多担忧。人们普遍担心，人类工作者可能会被计算机所替代。但辛顿和包括 OpenAI 首席执行官Sam·Altman在内的许多知名技术专家一样，警告称人工智能系统可能开始独立思考，甚至可能试图控制或消灭人类文明。听到这样一位人工智能领域的顶尖研究者表达这样令人警醒的看法，实在令人震惊。

“人们说，这不过是高级的自动补全功能，”他在厨房里对我说。（他一生大部分时间都受到背痛的困扰，最终痛得无法忍受，以至于放弃了坐着。自2005年以来，他几乎没有坐过一个小时以上。）“让我们来分析一下。假设你想变得非常擅长预测下一个词。要做到这一点，你必须理解正在说的话。这是唯一的方法。因此，通过训练一个系统来精准预测下一个词，你实际上是在迫使它去理解。没错，它是‘自动补全’——但你可能没有深入思考过一个真正优秀的自动补全功能意味着什么。”辛顿认为，“大型语言模型”，比如为 OpenAI 的聊天机器人提供动力的 GPT，能够理解单词和概念的含义。

那些认为我们对人工智能能力评估过高的怀疑论者指出，人类思维与神经网络之间存在显著差异。一个关键区别在于，神经网络的学习方式与我们迥然不同：我们通过亲身经历事物并理解它们与现实及自我之间的联系来获取知识，而神经网络则是通过处理大量关于它们并未真正存在的世界的信息来进行抽象学习。然而，Hinton认为，人工智能系统所展现的智能已经超越了其人造本质。

“当你进食时，你摄入食物并将其分解成微小的组分，”他对我说。“因此，你可以说我的身体部分是由其他动物的组分构成的。但这种说法其实颇有误导性。”他相信，通过分析人类的写作，像 GPT 这样的大型语言模型能够学习到世界的运作方式，从而形成一个具有思考能力的系统；而写作仅仅是这个系统能力的一部分。“这就像毛虫变成蝴蝶的过程，”他接着说。“在蛹期，你把毛虫变成了一种液体——从这种液体中你构建出蝴蝶。”

他开始在厨房旁边的一个小橱柜里寻找东西。“找到了！”他说。他以一种夸张的姿态，把一个物体放在了柜台上——一只完美保存的死蜻蜓。“我在码头发现的，”他解释说。“它刚在岩石上孵化出来，正在晾干翅膀，所以我抓住了它。看看它的下面。”Hinton捕捉到这只蜻蜓正是在它从幼虫形态变化之后。幼虫是一种外观完全不同的昆虫，有自己的眼睛和腿；它的背部有一个洞，蜻蜓就是从这个洞爬出来的。

“蜻蜓的幼虫就像水下的怪兽，”Hinton说。“它就像电影《异形》中的场景，蜻蜓从这个怪兽的背部破壳而出。幼虫经历了一个变成汤的阶段，然后蜻蜓就从这种汤中诞生。”在他的比喻中，幼虫象征着用于训练现代神经网络的数据；而蜻蜓则代表了由此诞生的敏捷的人工智能。深度学习——Hinton所推动的技术——促成了这一变革。我俯身仔细观察；Hinton则站得笔直，他几乎总是保持这样的姿态，以保护他的身体姿势。“它非常美丽，”他轻声说。“你明白我的意思。它从一种形态开始，变成了完全不同的东西。”

几周前，当Hinton邀请我访问他的岛屿时，我想象了各种可能的场景。也许他是一个喜欢独处的内向者，或者是一个拥有上帝情结和未来主义设施的科技大亨。在我到达之前的几天，他给我发了一张他拍摄的岛上草地上盘踞的响尾蛇的照片。我不确定是感到兴奋还是有些害怕。

实际上，Hinton的私人岛屿相当简朴，总共只有两英亩。Hinton本人与硅谷的c程序员完全不同。现年75岁的他，有着像乔舒亚·雷诺兹画作中的英国面孔，白发衬托着宽阔的额头；他的蓝眼睛通常很平静，让他的嘴巴表达情感。作为一个喜欢讽刺的讲故事者，他喜欢谈论自己——“‘杰夫’是‘自我最强’的变位词，”他告诉我——但他并不自我中心；他的生活因为悲伤而无法如此。“我应该告诉你关于我的妻子们的事情，”我们第一次交谈时他说。“我有过三次婚姻。一次和平结束，另外两次以悲剧告终。”他仍然与他的第一任妻子乔安妮保持友好关系，他们早年结婚，但他的第二任和第三任妻子，罗莎琳德和杰基，分别在1994年和2018年因癌症去世。过去四年，Hinton与退休的社会学家罗斯玛丽·加特纳在一起。“我认为他是那种总是需要伴侣的人，”她温柔地告诉我。他是一个将感性与科学平衡地融合在一起的浪漫理性主义者。在小屋里，一只酒红色的独木舟静静地放在占据大部分一楼的单一大房间里；他和杰基在岛上的树林中发现了它，当时已经损坏，杰基是一位艺术史学家，在她生病的那些年里，与一些女性独木舟制造者一起修复了它。“她进行了首航，”Hinton说。从那以后没人再使用它。

他收好了蜻蜓，然后走到一个小型立式办公桌旁，那里放着一台笔记本电脑，旁边是一堆数独游戏和一个装有电脑密码的笔记本。（他很少使用这个笔记本，因为他设计了一个助记系统，可以在脑中生成和回忆非常长的密码。）“我们来做家谱吧？”他问。他用两个手指输入了“Geoffrey Hinton 家谱”并按下回车键。2013年谷歌收购Hinton的初创公司时，部分原因是该团队找到了一种方法，使用神经网络大幅改进图像识别；现在无数的家谱在屏幕上涌现。

Hinton出身于一个特殊类型的英国科学家家庭：政治上激进，不断创新。在他家谱的上方是他的曾祖叔塞巴斯蒂安·辛顿，丛林健身架的发明者，以及他的表亲琼·辛顿，曼哈顿计划的物理学家。再往上，露西·埃弗雷斯特，成为皇家化学研究所选举成员的第一位女性；查尔斯·霍华德·辛顿，创造了四维空间入口概念的数学家（电影《星际穿越》中出现了一个）；以及詹姆斯·辛顿，一位开创性的耳科医生和多妻制的倡导者。（据说他曾评论说：“基督是男人的救世主，但我是女人的救世主。”）在十九世纪中叶，辛顿的曾曾祖父，英国数学家乔治·布尔，开发了二进制推理系统，现在称为布尔代数，这是所有计算的基础。布尔娶了玛丽·埃弗雷斯特，一位数学家和作家，也是乔治·埃弗雷斯特的侄女，后者是珠穆朗玛峰命名者的测量员。

“杰夫天生就是科学家，” Geoffrey Hinton的前学生兼现任 Meta 人工智能部门负责人 Yann LeCun 说。但Hinton的家庭背景比这更为奇特。他的父亲霍华德·埃弗雷斯特·辛顿在二十世纪初的墨西哥革命时期，在其父亲经营的银矿中长大。辛顿回忆说，他的父亲非常坚韧：据家族传说，霍华德曾在十二岁时因为不满拳击教练的严厉而威胁要射杀他，导致教练最后离开了小镇。霍华德的母语是西班牙语，他在伯克利大学受到了因口音而来的嘲笑。“他与一群同样遭受歧视的菲律宾人交往，并成为了伯克利的激进分子，” Hinton说。霍华德的政治观念不仅局限于马克思主义，还包括斯大林主义：1968年，当苏联坦克进入布拉格时，他曾说，“该来的终于还是来了！”

Hinton在学校时就对科学充满兴趣。但由于意识形态的原因，他的父亲禁止他学习生物学，因为霍华德认为遗传决定论与共产主义关于人性可塑性的信仰相悖。（“我对所有形式的信仰都感到厌恶，” 辛顿回忆说。）霍华德在布里斯托尔大学教授昆虫学，他像电影中的印第安纳·琼斯一样，将世界各地的珍稀生物偷运回英国，并编辑了该领域的重要期刊。同样以埃弗雷斯特为中间名的Hinton感受到了巨大的压力，希望能在科学上有所成就。他回忆起父亲曾对他说：“如果你比我努力两倍，等你到了我这个年龄，你可能会达到我一半的成就。”

在剑桥大学，Hinton尝试过多个学科，但他感到沮丧，因为在任何一个班级里，他都不是最优秀的学生。他曾暂时离开学校，到伦敦去阅读一些忧郁的小说，并做些临时工作。后来，他回到大学，尝试了一天的建筑学。在探索了物理学、化学、生理学和哲学之后，他最终选择了实验心理学作为自己的专业。他经常参加哲学家伯纳德·威廉姆斯的讨论会，发现威廉姆斯对计算机和心理学很感兴趣。有一次，威廉姆斯提出了一个观点：我们的不同思想必须对应大脑内部不同的物理结构，这与计算机内软件与硬件相互独立的情况完全不同。这一点深深触动了Hinton；他回想起高中时，一个朋友曾告诉他，记忆可能以“全息”的形式存储在大脑中，即分散存储，但可以通过任何部分访问整体。他接触到的是“连接主义”——这是一种结合神经科学、数学、哲学和编程的方法，用以探索神经元如何共同“思考”。连接主义的目标之一是在计算机中创造一个类似大脑的系统。这方面已经取得了一些进展：在20世纪50年代，心理学家和连接主义的先驱弗兰克·罗森布拉特设计了一台名为“感知器”的机器，它利用简单的计算机硬件模拟了数百个神经元的网络。当连接到光感应器时，这台设备能够通过追踪不同光线模式激活的人工神经元来识别字母和图形。

在小屋内，Hinton 来回踱步，穿梭于厨房和一楼的各个角落。他准备了一些吐司，给我们每人递了一个苹果，接着用一个脚踏凳搭建了一个临时的小桌子。家族的期望曾迫使他放弃了短暂的满足感。“我一直对木工情有独钟，”他边吃边怀旧地说，“在学校，晚上可以自愿做木工。我常想，如果我成为了建筑师，可能会更快乐，因为那是我乐意做的事。而在科学领域，我总得逼迫自己前进。因为家族的期望，我必须在这条路上取得成就——我必须找到自己的道路。虽然其中有乐趣，但更多的是焦虑。现在，我终于取得了成功，这让我感到莫大的释然。”

自从离开 Google 后，Hinton 的邮箱里充斥着各种关于人工智能的咨询请求。他走过去查看了一封邮件，随后又陷入了对家族树的研究中，这些家族树似乎都存在着这样或那样的错误。

“看看这个，”他说。

我走过去，看着电脑屏幕。上面展示的是一个“学术家谱”，顶端是 Hinton 和他的学生们，以及他们的学生们。这个家谱非常庞大，Hinton 不得不横向滚动屏幕来查看他的影响力。“哎呀，”他边浏览边说，“她其实不是我的学生。”他继续向下滚动。“他很有才华，但作为导师就不太行，因为他总是能自己做得更好。”Hinton 似乎特别喜欢看到自己的学生超越他：在评估求职者时，他曾经问过他们的导师：“他们比你更出色吗？”谈到1977年去世的父亲时，Hinton 说：“他非常好胜。我一直在想，如果他还活着，看到我取得的成功，他是否会真心高兴。因为现在我比他更成功。”

根据 Google Scholar 的数据，Hinton 现在是心理学领域中引用次数第二多的研究者，同时也是计算机和认知科学领域中引用次数最多的。他在剑桥的起步虽然缓慢且有些古怪，但这部分是因为他在探索一个新兴的研究领域。“神经网络——在顶尖大学里研究这个的人很少，”他说，合上笔记本电脑。“在麻省理工、伯克利或斯坦福都做不了这个。”成为一个新兴领域的中心人物有其独特优势。多年来，许多顶尖的智慧都汇聚到了他这里。

“今天天气不错，”Hinton 第二天早上说，“我们可以去砍棵树。”他身着正装衬衫，塞进卡其裤里，看上去并不像个伐木工，但他还是摩拳擦掌。在这个岛上，他总是忙着砍树，以营造更整齐美观的环境。

房子本身也是一个持续进行的项目。很少有承包商愿意来到这么偏僻的地方，Hinton 雇佣的工人们犯下了一些不必要的错误，比如让排水管反向安装，或是只完成一半的地板，这些至今仍让他感到愤怒。几乎每个房间都有待修正的小项目。在我访问时，Hinton 在这些地方都贴上了小便签，以指导新的承包商，他甚至直接在建筑材料上写字。在一楼的浴室，一块踢脚板靠在墙上，上面写着“浴室应该用这种踢脚板（只在淋浴区前的枫木饰条）”。在客房的衣柜里，一个架子上贴着遮光胶带，上面写着：“不要给架子打底漆，只给支撑架打底漆。”

在爱丁堡大学攻读人工智能博士学位时，Hinton 沉思着如何在计算机中模拟大脑的“认知”过程。在20世纪70年代，大多数人工智能研究者信奉“符号主义”。他们认为，理解某样东西，比如番茄酱，需要涉及许多概念，例如“食物”、“酱料”、“调味品”、“甜味”、“鲜味”、“红色”、“番茄”、“美国”、“薯条”、“蛋黄酱”和“芥末”等；这些概念共同构成一个框架，新的概念如“番茄酱”就可以基于此搭建。一个名为 Cyc 的大型、资金雄厚的人工智能项目致力于建立一个庞大的知识库，科学家们可以用特殊的语言来输入概念、事实和规则，以及它们的例外情况（例如，鸟类能飞，但企鹅或受伤的鸟则不行……）。

然而，Hinton 对这种方法持有疑虑。他觉得这种方法过于僵硬，太过专注于哲学家和语言学家所具备的推理技能。他明白，在自然界中，许多动物在没有用语言表达的概念的情况下也能表现出智能。它们通过经验学习如何变得聪明。在他看来，学习而非知识，才是智能的真正动力。

复杂的人类思考通常似乎依赖于符号和文字。但 Hinton 及其合作伙伴 James L. McClelland 和 David Rumelhart 相信，许多思考活动实际上发生在概念之下的层面。他们指出，当你了解到某个对象的新信息时，你对其他类似对象的看法也会相应改变。比如，如果有人告诉你黑猩猩喜欢洋葱，你可能会推测大猩猩也喜欢洋葱。这暗示了知识在大脑中可能是以“分布式”形式存在的，由能够在相关思想间共享的更小的构建块组成。这意味着，大脑中不会有两个独立的神经网络分别代表“黑猩猩”和“大猩猩”；而是通过激活代表各种具体或抽象特征（如毛茸茸、四足、灵长类特征、动物性、智能、野性等）的神经元束，以不同的方式表达“黑猩猩”和“大猩猩”。这种心智构造方式可能会导致混淆和错误，但如果大脑拥有正确的学习算法，就能调整神经元间的权重，偏向于合理的组合而非混乱的组合。

Hinton 继续在这一领域深入研究。他先是在加州大学圣地亚哥分校完成博士后研究（期间与他指导的 Joanne 结婚），然后在剑桥大学担任应用心理学研究员，最后在1982年成为匹兹堡卡内基梅隆大学的计算机科学教授。在卡内基梅隆，他将大部分研究资金投入到购买一台强大的计算机上，用以运行神经网络。他不久后与分子生物学家 Rosalind Zalin 结婚。在卡内基梅隆，Hinton 取得了重大突破。他与计算机科学家兼神经科学家 Terrence Sejnowski 合作，开发了名为 Boltzmann Machine 的神经网络。这个系统以19世纪奥地利物理学家 Ludwig Boltzmann 的名字命名，他数学上描述了气体的宏观行为与其微观粒子行为之间的关系。Hinton 和 Sejnowski 将这些方程与学习理论相结合。

Hinton 对于向我解释 Boltzmann Machine 显得有些犹豫。他比喻说：“这就像带着一个小孩去爬山。你要带着这个孩子走上山顶，然后再下来。”他看着我——在这个比喻中，我是那个孩子——并叹了口气。他担心我可能会因为简化的解释而误解，进而误导他人。“试图解释你自己都不理解的复杂概念是徒劳的。首先，你必须真正理解事物的运作方式。否则，你只会说出无意义的话。”最终，他拿出一些纸张，开始绘制神经元和连接它们的箭头的图表，并写下方程式，我努力理解。（在访问之前，我已经上过 Khan Academy 的线性代数课程。）

他建议，理解 Boltzmann Machine 的一种方法是将其想象成一个 Identi-Kit：一个系统，可以通过组合各种面部特征——如浓眉、蓝眼睛、歪鼻子、薄嘴唇、大耳朵等——来制作一种综合肖像，类似于警察用的那种。为了使 Identi-Kit 起作用，这些特征本身必须被恰当地设计。Boltzmann Machine 不仅能学习如何组合这些特征，还能通过改变其人工神经元间连接的权重来设计这些特征。它会从随机特征开始，这些特征最初看起来像电视屏幕上的雪花，然后通过“醒着”和“睡着”两个阶段来改进它们。在醒着的阶段，它会调整特征，使其更好地匹配真实的面孔。在睡着的阶段，它会幻想一个不存在的面孔，然后调整特征，使它们更不匹配。

图片

它的梦境告诉它不应该学习什么。这个系统具有一种优雅之美：随着时间的推移，它能够从错误中摆脱出来，逐渐接近现实。它不需要别人告诉它什么是对的或错的——它只需要观察现实世界中存在的事物，并梦想那些不存在的事物。

Hinton 和 Sejnowski 在 1983 年发表了一篇关于 Boltzmann Machine 的论文。Yann LeCun 回忆说：“当我开始我的研究生生涯时，我读到了这篇论文，我立刻想，‘我必须和这些人交流——他们是世界上唯一意识到我们需要学习算法的人。’”在 80 年代中期，现任魁北克人工智能研究所 Mila 科学总监、自然语言处理和计算机视觉领域的先锋 Yoshua Bengio，为了他的硕士论文，训练了一个 Boltzmann Machine 来识别口语音节。“Geoff 是论文的外部评审之一，”他回忆说，“他曾写道‘这不应该有效’。”然而，Bengio 的 Boltzmann Machine 版本比 Hinton 预期的要有效得多；Bengio 花了几年时间才理解其中的原因。这种情况后来变得司空见惯。在随后的几十年中，神经网络通常会表现得比预期更好，可能是因为在训练过程中神经元之间形成了新的结构。“实验往往先于理论，”Bengio 回忆说。通常，这就是尝试新方法并观察网络的反应。

部分是因为 Rosalind 对罗纳德·里根的厌恶，Hinton 说，他们搬到了多伦多大学。他们从拉丁美洲收养了一对儿女，住在城市里的一所房子中。“我是那种全心投入工作的社会主义教授，”Hinton 说。

Rosalind 曾经因为不孕问题与不体贴的医生有过不愉快的经历。这可能是她后来在被诊断出患有卵巢癌时选择顺势疗法的原因。Hinton 说：“这完全讲不通。不可能是药物越稀释，效力就越强。”他无法理解一个分子生物学家怎么会转向顺势疗法。尽管如此，Rosalind 决定自行治疗癌症，即使在发现一个巨大肿瘤后也拒绝接受手术；后来，她虽然接受了手术，但拒绝了化疗，转而在加拿大和瑞士寻求越来越昂贵的顺势疗法。她的病情恶化，出现了继发性肿瘤。她甚至要求 Hinton 卖掉他们的房子来支付新的治疗费用。“我在那时拒绝了，”他回忆时眼中闪现着痛苦。“我说，‘不，我们不能卖房子。如果你去世了，我得照顾孩子们，对他们来说留在这里更好。’”

Rosalind 回到加拿大后立即入院治疗。她坚持了几个月，但直到临终前一天才让孩子们来看她，因为她不想让他们看到自己病重的样子。在她生病期间，她始终相信自己会很快康复。Hinton 在描述这一切时，仍然感到难以置信——他感到愤怒、内疚、伤心和困惑。当 Rosalind 去世时，Hinton 46 岁，他的儿子 5 岁，女儿 3 岁。“她因为不愿接受即将离世的事实，伤害了周围的人，”他说。

午后的宁静被海浪的声音打破。强烈的阳光从落地窗洒进屋内，窗户上的蜘蛛网在光影中若隐若现。Hinton 站了一会儿，似乎在整理自己的思绪。

“我想我得去砍棵树，”他说。

我们从前门出发，沿着小径走向工具棚。Hinton 从一个棚子里拿出了一把小型绿色链锯和安全护目镜。

“Rosemary 说，如果我一个人在场，就不许我砍树，以免我不小心伤到自己，”他说。“你开过船吗？”

“没有，”我回答。

“那我得特别小心，别砍伤了我的右手。”

他在卡其裤外面套上了一副防护裤。

“我不想让你以为我很懂这个，”他说。“但基本上，就是砍几个 V 字型，然后树就会倒下。”

Hinton 走向他选定的那棵树，一边走一边留意灌木丛中是否有蛇。那是一棵约二十英尺高的茂盛雪松；他仰头观察树的倾斜方向，然后启动链锯开始在树干的相反侧切割。他切了一个 V 字型后停下来转向我。“因为树是向着切口的反方向倾斜的，所以当你切得更深时，V 字会逐渐打开，这样锯片就不会卡住，”他解释道。

Hinton 一言不发地操作着链锯，不时停下来擦去额头上的汗珠。在炽热的阳光下，蚊虫在阴凉处成群结队。我观察了工具棚旁，那里的蚂蚁和蜘蛛正忙于他们神秘而永无休止的活动。小径尽头，水面波光粼粼。这是一个美丽的地方。然而，我似乎理解了 Hinton 想要改变这里的原因：一个优美的圆形小山坡渐渐下降至一个平和的凹地，如果那棵不必要的树被砍掉，阳光就能流淌进这个空间。那棵树似乎是个错误。

最后，他在树的另一边开始了第二次切割，朝着第一个切口斜切。接着他来回移动，不断加深两个切口，使树木逐渐接近倒塌的临界点。突然，几乎无声地，树木在重力的作用下缓缓倒下，轻轻地落在凹地底部。阳光随之洒满整个空间。

Hinton 对 Boltzmann Machine 深深着迷。他希望它或其类似的机制能成为大脑学习过程的基础。“这应该是对的，”他对我说。“如果我是上帝，我会确保它是真实的。”然而，随着进一步的实验，他们发现，随着 Boltzmann Machines 的扩展，它们趋向于被内在的随机性所淹没。“我和 Geoff 对于 Boltzmann Machine 的看法不同，”LeCun 说。“Geoff 认为它是最美妙的算法。我却觉得它很粗糙。它是基于随机性的。”与此相反，LeCun 认为，“backprop 算法非常简洁。”

“Backprop”，即反向传播，是一种早在 1960 年代就由几位研究者开始探索的算法。即便在 Hinton 与 Sejnowski 合作研究 Boltzmann Machine 的同时，他也在与 Rumelhart 和另一位计算机科学家 Ronald Williams 探索 backprop。他们认为这种技术在学习方面有巨大的未开发潜力，特别是他们希望将其与多层次的神经网络结合使用。

理解 backprop 的一个方法是将其比作一个类似卡夫卡小说中的司法系统。想象神经网络的上层是一个永无休止审判案件的陪审团。陪审团刚做出了一个裁决。在 backprop 这个反乌托邦世界中，法官可以告诉陪审员他们的裁决是错误的，并且他们会因此受到惩罚，直到他们改正。陪审团中有三个成员对引导团队做出错误决定起到了关键作用。这种责任分配是反向传播的第一步。

接下来，这三个误判的陪审员开始探究自己是如何被误导的。他们回顾了影响他们的因素——父母、老师、专家评论员等——并找出了那些误导他们的人。这些应受指责的影响者反过来也要找出影响他们的人，并在他们之间分配责任。随着每一层影响者都在追溯自己的影响源头，开始了一轮又一轮的责任推诿，形成了一种向后扩散的连锁反应。最终，当明确了谁误导了谁以及误导的程度后，网络会相应地调整自己，让个体对“坏”影响的听从减少，对“好”影响的听从增加。这个过程反复进行，精确到数学级别，直到所有案件中的裁决都尽可能地接近“正确”。

1986年，Hinton、Rumelhart 和 Williams 在《Nature》杂志上发表了一篇研究神经网络如何运作的三页论文。他们提到，虽然 backprop（反向传播算法）和 Boltzmann Machine（玻尔兹曼机）并不完全符合大脑学习的模型——毕竟大脑无法像计算机一样回溯过去的表现——但 backprop 仍促进了类似大脑的神经元专业化发展。例如，在视觉系统中，不同的神经元专注于识别图像的边缘。类似的专业化也出现在 backprop 网络中，其中某些层会专门用于识别线条、曲线或边缘，以帮助网络逐步形成有效的内部解读机制。

五六十年代，感知机（Perceptron）等联结主义研究激起了巨大的热情，但随后这股热情逐渐消退。backprop 论文的发表标志着对这一领域兴趣的复苏，并引起了广泛关注。然而，由于实际和概念上的限制，构建 backprop 网络的进程缓慢。从实际角度来看，当时的计算机运行效率低下，Hinton 回忆道，他们常常评估一台计算机一夜之间能学到多少，而结果通常并不理想。从概念角度来看，神经网络的运作原理颇具神秘感，不同于传统编程方法，人们无法直接编辑人工神经元间连接的权重，而且权重的具体意义难以理解，因为它们会在训练过程中自我调整和变化。

在神经网络的学习过程中，存在许多潜在的问题。例如，“过拟合”现象中，网络倾向于仅记忆训练数据，而非从中抽象出普遍规律。避免这些问题并非易事，因为网络本身承担着学习的任务。这就像砍树一样，研究者只能在某些部位做出调整，然后让剩余的过程自然发展。他们尝试了各种技术，如“集成”（组合弱网络以形成强大的网络）和“早停”（让网络学习，但适度控制），还有“预训练”，即先让 Boltzmann Machine 学习一些基本知识，再加上 backprop 网络，希望网络能自我学习到一定程度。

同时，新的神经网络“架构”，如“循环”和“卷积”网络，通过不同的方式帮助系统自我进化。但对于研究人员来说，这就像是发现了一项未知的外星技术。他们试图从混乱中找到规律，就像解魔方一样。Hinton 曾说：“我始终坚信这不是无稽之谈。这不仅仅是信念——对我来说，这是显而易见的。”由于大脑通过神经元学习，他相信通过神经网络实现复杂学习是可能的。为此，他愿意付出双倍的努力，投入双倍的时间。

在使用 backprop 算法训练神经网络时，网络需要明确知道自己的错误及其程度，这就要求有大量准确标记的数据，以便网络能区分细微差别，比如手写数字“7”和“1”，或金毛寻回犬和红色爱尔兰雪达犬的区别。然而，找到大规模且标记准确的数据集非常困难，构建新的数据集更是费时费力。LeCun 和他的团队创建了一个庞大的手写数字数据库，后来这个数据库被用来训练网络，使其能识别美国邮政服务提供的邮编样本。斯坦福大学的计算机科学家 Fei Fei Li 发起了一个名为 ImageNet 的宏大项目，该项目涉及收集超过一千四百万张图片，并手动将它们分为两万个类别。

随着神经网络规模的扩大，Hinton 发明了一种方法，可以将大型网络的知识“蒸馏”到小型网络中，这些小型网络可以在移动电话等设备上运行。他在厨房里解释这个过程：“就像在学校里，美术老师展示不同画家的作品，而不仅仅是告诉你这是谁的作品，还会指出一些画作的特别之处，比如一幅提香作品中与拉斐尔风格相似的元素。这种讲解方式更有帮助。”在蒸馏学习中，一个神经网络不只是提供正确答案，还会提供一系列可能的答案及其可能性。这种方法赋予网络更为丰富和深入的知识。

在 Rosalind 去世几年后，Hinton 重逢了艺术史学家 Jacqueline Ford，他们曾在 Hinton 前往美国前短暂交往过。Jackie 既有文化涵养又温暖、好奇、美丽。“她不是你的对手，”他的姐姐曾说。但 Jackie 还是放弃了英国的工作，移居到多伦多。他们于 1997 年 12 月 6 日——Hinton 五十岁生日那天结婚。此后的几十年成为了他一生中最幸福的时光，家庭再度完整，孩子们也喜欢上了他们的新妈妈。他和 Jackie 一起开始探索 Georgian Bay 的岛屿。Hinton 回忆说，他们在树林里发现了一艘翻覆的、被帆布覆盖的独木舟，它已经完全腐烂，但 Jackie 决定还是要修复它，就像她挽救了他和孩子们一样。

Hinton 对 backpropagation 并不情有独钟。“从智力角度来看，这种方法并不让人满意，”他说。与 Boltzmann Machine 不同，backpropagation 完全是确定性的，可惜的是，它的效果确实更好。随着实践进展的累积，backprop 的力量变得不可忽视。Hinton 说，在七十年代初，英国政府曾聘请数学家 James Lighthill 来评估人工智能研究是否有希望成功。Lighthill 认为没有，这在当时是正确的，因为大家普遍认为计算机的速度可能提升千倍，但不可能提升十亿倍。Hinton 曾做过一个头脑计算：假如他在 1985 年开始在一台快速的研究计算机上运行一个程序，一直运行到现在，而如果他现在在当前最快的人工智能系统上运行同一个程序，追赶上之前的进展只需不到一秒钟。

在 2000 年初，随着配备强大计算能力的多层神经网络开始在庞大的数据集上进行训练，Hinton、Bengio 和 LeCun 开始探索“深度学习”的前景。这一领域在 2012 年取得重大突破，Hinton、Alex Krizhevsky 和 Ilya Sutskever 发布了 AlexNet，一个八层的神经网络，能够以人类水平的准确度识别 ImageNet 中的物体。随后，Hinton 与 Krizhevsky 和 Sutskever 合作成立了一家公司，并将其出售给了 Google。他和 Jackie 在 Georgian Bay 买了一座岛屿，Hinton 称这是他唯一的奢侈。

两年后，Jackie 被诊断出患有胰腺癌。医生预计她只能再活一到两年。“她非常勇敢、理性，”Hinton 回忆道。“她并未陷入深度否认，而是选择面对现实。她认为自己可以选择为自己感到遗憾，或者把剩下的时间用来尽享生活，同时为他人着想。”在选择治疗方法之前，他们一起仔细研究了统计数据；主要通过化疗，她将生命延长到了三年。当 Jackie 无法走楼梯时，Hinton 在小屋里为她制作了一个小篮子，以便她可以把茶从楼上降到楼下让他加热。（“我本该直接把微波炉搬到楼上，”他说。）

那天晚些时候，我们靠在 Hinton 的站立办公桌旁，他向我展示了 Jackie 的照片。在他们婚礼那天的照片中，他和 Jackie 站在邻居家的客厅里，与他的孩子们一起宣誓。Hinton 看起来非常放松且容光焕发；Jackie 用双手轻轻握着他的一只手。在他给我看的最后一张照片中，Jackie 正从她修复的酒红色独木舟上，凝视着相机。“那是 2017 年夏天的事，”Hinton 说。Jackie 在次年四月去世。同年六月，Hinton、Bengio 和 LeCun 获得了计算机科学界的最高荣誉——图灵奖。

Hinton 确信，从某种真实的角度来看，神经网络能够产生感觉。“我认为感觉是对可能引发行动的事情的一种设想，”他之前告诉我。“比如，我想要打某人一拳。这意味着，如果没有社交约束，如果我不制止自己，我就会这样做。所以，当我说‘我感到愤怒’时，其实是在简化地表达‘我想做攻击性行为’。感觉只不过是表达行动倾向的一种方式。”

他分享了他在 1973 年看到的一台“沮丧的人工智能”的经历。一台计算机连接了两个摄像头和一个简单的机器臂，任务是把散落在桌子上的积木组装成玩具车。他回忆说，这在当时非常困难。如果积木堆放在一起，视觉系统就无法识别它们。计算机的解决办法是，稍微退后一些，然后猛地打散积木。这就像是它无法处理眼前的情况，于是通过暴力改变现状。如果人这么做，我们会说他们感到沮丧。拥有感觉就像是渴望那些无法得到的东西。

“我爱这所房子，但有时它让人感到悲伤，”他在看照片时说。“因为她曾经喜欢这里，但现在不在了。”

太阳即将落山，Hinton 打开了桌上的小灯。他关上电脑，推了推眼镜，重新回到现实中。

“我想让你了解 Roz 和 Jackie，因为他们是我生命中重要的一部分，”他说。“但实际上，这对于理解人工智能也很重要。面对人工智能，有两种态度：否认和坚忍。大多数人的第一反应是‘我们必须阻止这一切’，就像面对癌症时，大家首先想到的是‘如何切除它’。”但他强调，重要的是要认识到，有时切除只是一种幻想。

他叹了口气。“我们不能否认现实，”他说。“我们必须面对现实。我们需要思考，如何让人工智能对人类的影响不那么恶劣？”

人工智能将会变得多么有用或危险？目前尚无人能确切回答这个问题，部分原因是神经网络本身具有神秘性。二十世纪的许多研究者致力于打造能模仿人类大脑的计算机。尽管像 OpenAI 的 GPT 模型这样的神经网络涉及数十亿个人工神经元，与大脑在某种程度上相似，但它们实际上与生物大脑有着本质的不同。今天的人工智能系统基于云端，部署在消耗大量能源的数据中心中。这些系统在某些方面显得无知，在其他方面则表现出惊人的能力，它们为数百万用户进行思考，但只在被激活时才这么做。它们并不是活生生的存在。它们可能已经通过了图灵测试——按照计算先驱艾伦·图灵的标准，任何能在对话中令人信服地模仿人类的计算机都可以被认为具有思考能力。然而，我们的直觉或许会告诉我们，浏览器标签页中的东西不可能真正地进行思考。这些系统迫使我们重新思考，我们所认为的思考方式是否是唯一有效的。

在谷歌的最后几年里，Hinton 把重点放在利用更类似大脑的硬件来创建更传统的、类似于人类思维的人工智能上。在现代的人工智能系统中，人工神经元之间的连接权重以数字形式存储，就像大脑对自己的功能保持记录一样。然而，在真实的、模拟的大脑中，这些权重是构建在神经元之间的物理连接上的。Hinton 致力于利用专门的计算机芯片来构建这种系统的人工版本。

“如果能实现，那将是非凡的成就，”他告诉我。这些芯片通过改变其“导电性”来学习。由于权重被直接融入硬件，无法从一台机器复制到另一台，因此每个人工智能都必须独立学习。“它们需要接受教育，”他说。“但这将能够将能源消耗从一兆瓦降低到三十瓦。”他说这话时，身体前倾，目光紧盯着我；我看到了 Hinton 作为一名狂热传教士的一面。他将这种方法称为“凡人计算”，因为每个人工智能获取的知识在拆解时会丢失。“我们将放弃永恒不朽，”他说。“就像在文学作品中，为了心爱的女人放弃成神的权力一样。这里，我们得到的是更重要的东西——能源效率。”能源效率鼓励个体化：因为人脑可以在燕麦的滋养下运作，这使得世界能够支撑数十亿个不同的大脑。每个大脑都能持续学习，而不是接受一次性的训练然后进入世界。

作为一项科学事业，凡人 AI 可能使我们更接近复制自身大脑的目标。但 Hinton 认为，数字智能可能更为强大。在模拟智能中，“大脑一旦死亡，知识随之消失，”他说。而在数字智能中，“即使特定计算机死亡，相同的连接强度可以在另一台计算机上使用。甚至如果所有数字计算机都消亡，只要将连接强度存储在某处，就可以在另一台数字计算机上运行相同的权重。一万个神经网络可以同时学习一万种不同的事物，然后共享他们所学到的。”他说，这种不朽和复制性的结合意味着，“我们应该对数字智能取代生物智能表示担忧。”

如何描述没有凡人躯体或个体身份的数字智能的心理活动？最近，一些 AI 研究人员开始将 GPT 称为“推理引擎”，这可能是他们试图避开“思考”这个难以定义的词汇带来的负担。“人们责怪我们使用‘思考’、‘知晓’、‘理解’、‘决策’等词语，”Bengio 对我说。“但虽然我们对这些词的完整含义理解不足，它们作为创造类比的手段极大地帮助了我们理解自己的工作。用‘想象力’、‘注意力’、‘计划’、‘直觉’这类词汇来阐明和探索对我们大有裨益。”在 Bengio 看来，“我们所做的很多工作实际上是在解决心智中的‘直觉’问题。”直觉可能被理解为我们无法解释的思维：我们的大脑无意识地为我们生成直觉，通过将当前遭遇与过去的经验联系起来。我们通常将理性看得比直觉更重要，但 Hinton 认为，我们比自己意识到的更依赖直觉。“多年来，符号 AI 研究者认为我们的本质是推理机器，”他说。“我认为那是无稽之谈。我们的本质其实是类比机器，上面叠加了一些推理功能，用于在类比得出错误答案时进行纠正。”

总体来看，当前的 AI 技术偏向于言语和理性：在与物理世界接触的边界上显得笨拙。“任何青少年都能在二十个小时的练习中学会开车，几乎无需监督，”LeCun 对我说。“任何猫都能跳上一系列家具，到达某个架子的顶部。但我们现在还没有任何 AI 系统能接近完成这些任务，自动驾驶汽车除外”——而且它们的设计过于复杂，需要“绘制整个城市的地图、数百名工程师的努力和数十万小时的训练。”LeCun 说，解决物理直觉方面的问题“将是下一个十年的重大挑战。”但基本的思路很简单：如果神经元可以做到，那么神经网络也应该能够实现。

Hinton 怀疑，人们对人工智能潜能的怀疑态度，尽管给人安慰，但往往源于对人类特殊性的不合理信仰。研究人员抱怨 AI 聊天机器人在遇到难题时“幻想”，编造出看似合理的答案。但 Hinton 对这种说法提出了质疑。“我们应该说‘杜撰’，”他对我说。“‘幻觉’意味着你认为有感官输入，如听觉、视觉、嗅觉幻觉。但仅仅编造东西是杜撰。”他举了约翰·迪恩的例子，尼克松总统的白宫法律顾问在他得知自己描述的对话被录音之前接受了关于水门事件的采访。迪恩杜撰了细节，混淆了谁说了什么。“但大体上是正确的，”Hinton 说。“他回忆了所发生的事情，并将这些回忆强加到他脑海中的角色上。这就是人类记忆。在我们的思维中，编造和说实话之间没有明显界限。说实话实际上就是正确地编造。因为这一切都在权重中，对吧？”从这个视角看，ChatGPT 的编造能力虽是缺陷，但也显示了它的人类智能特征。

Hinton 经常被问及他是否后悔从事他的工作。他并不后悔。（他最近向一位记者发送了一条消息：“一首歌给你”，附上一条链接到艾迪特·皮雅芙的《Non, Je Ne Regrette Rien》。）他说，当他开始研究时，没人认为这项技术会成功；即使在它开始取得成功时，也没人认为它会如此迅速地成功。正因为他认为人工智能真正具有智能，他预期它将对许多领域做出贡献。然而，他担心，比如强大的人滥用它时会发生什么。“你可以想象弗拉基米尔·普京制造一个自主致命武器，目标是杀害乌克兰人，”Hinton 说。他认为应该禁止自主武器——尽管美国军方正在积极开发它们——但警告说，即使是良性的自主系统也可能造成巨大破坏。“如果你想让一个系统高效，你需要给它创造自己的子目标的能力，”他说。“问题在于，有一个通用的子目标几乎对所有目标都有帮助：获得更多控制。研究问题是：如何阻止它们永远不想要控制权？目前还没有人知道答案。”（他指出，控制不必是物理的：“它可能就像特朗普通过言语影响国会那样。”）

在这一领域，Hinton 的观点引发了不同的共鸣和争议。“我并不害怕人工智能，”LeCun 对我说。“我认为让它们的目标与我们的目标保持一致将会相对容易。”他继续说，“有一种观点认为，如果一个系统是智能的，它就会渴望主宰。但渴望主宰与智能无关，而是与睾酮有关。”我回想起我在小屋看到的蜘蛛，它们的网覆盖了 Hinton 的窗户。它们也并不渴望主宰——尽管它们的昆虫智能使它们扩大了领域。像蚂蚁群这样没有集中大脑的生命系统并不“想”做任何事，但它们仍能找到食物、渡过河流、并大量杀死竞争者。Hinton 和 LeCun 的观点都有可能是正确的。这场变革尚未完成。我们还不知道人工智能将发展成什么样。

“我们为什么不直接关闭它？”我问 Hinton，指的是人工智能。“这个问题完全不合理吗？”

“说‘没有这个我们会更好——这不值得’并不是不合理，”他回答。“就像我们可能没有化石燃料会更好。我们可能会更加原始，但这可能不值得承担的风险。”他从容地补充说，“但这不会发生。因为社会的运作方式。还有不同国家之间的竞争。如果联合国真的有效，可能有办法阻止这种情况。尽管即便如此，人工智能还是太有用了。它在医学等领域有极大的潜力做好事——当然，还能通过自主武器给国家带来优势。”今年早些时候，Hinton 拒绝签署一份要求至少暂停研究六个月的热门请愿。“中国不会停止它的发展六个月，”他说。

“那我们应该怎么办？”我问。

“我不知道，”他回答。“如果这个问题像气候变化那样就好了，那样人们可以说，看，我们要么停止燃烧碳，要么找到有效地从大气中移除二氧化碳的方法。在那种情况下，你知道解决方案是什么样的。但在这里，情况并非如此。”

Hinton 正在穿上一件蓝色防水夹克。我们正要去码头接 Rosemary。“她带来了补给！”他带着笑容说。当我们走出门时，我回头望了一眼小屋。在大房间里，酒红色的独木舟在阳光的照耀下闪闪发光。几把椅子半圆形地摆放在它前面，通过窗户望向水面。一些杂志堆放在小桌上。这是一个美丽的房子。人类的心智不仅仅是进行推理；它存在于时间之中，面对生死，围绕自身构建一个世界。它似乎自然而然地汇聚了意义。我想，人工智能或许能够想象这样的地方。但它真的会需要这样的地方吗？

我们沿着树木茂密的小径前行，经过小棚屋，走下通往码头的楼梯，然后登上 Hinton 的船。天空一片完美的蓝色，轻风在水面上激起波浪。Hinton 站在驾驶台旁。我坐在前面，看着其他岛屿逐渐远去，思考着人工智能的故事。对一些人来说，这是一则哥白尼式的故事，我们对人类心智特殊性的直觉正被思考机器颠覆。对其他人来说，则是普罗米修斯式的——我们偷来了火焰，冒着被烧伤的危险。有人认为我们自欺欺人，被我们自己的机器和企图从中获利的公司所欺骗。从某个角度看，这也可能是关于人类局限的故事。

如果我们是神，我们可能会创造一种不同的人工智能；但在现实中，这个版本是我们能够实现的。同时，我不禁从伊甸园的角度思考这个故事。通过试图重现我们大脑中的知识系统，我们夺取了禁果；现在我们面临着被逐出我们的美妙世界的风险。

但谁会选择不了解知识是如何工作的呢？

